{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "424be036",
   "metadata": {},
   "source": [
    "# 18 • Herramientas de texto\n",
    "\n",
    "En este notebook se revisará distintas herramientas para modificar, limpiar, preprocesar texto en Python.\n",
    "\n",
    "## Contenido\n",
    "1. Strings como lista de caracteres\n",
    "2. Preproceso de texto\n",
    "3. Regular expressions (*Regex*)\n",
    "4. spaCy\n",
    "5. Referencias  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84de6d17",
   "metadata": {},
   "source": [
    "## 1. Strings como lista de caracteres\n",
    "Anteriormente ya habían trabajado con strings, sin embargo, podemos tratar a un string como una lista de caracteres. Para esto, podemos utilizar los [métodos para *strings* que tiene Python](https://docs.python.org/3/library/stdtypes.html#string-methods)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffa5aa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"Mi viLLano faVorito\"\n",
    "\n",
    "# También se puede declarar así:\n",
    "# texto = str(\"Mi villano favorito\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c05fa8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M\n",
      "i\n",
      " \n",
      "v\n",
      "i\n",
      "L\n",
      "L\n",
      "a\n",
      "n\n",
      "o\n",
      " \n",
      "f\n",
      "a\n",
      "V\n",
      "o\n",
      "r\n",
      "i\n",
      "t\n",
      "o\n"
     ]
    }
   ],
   "source": [
    "# Un string es una cadena de caracteres y al imprimirlo con un loop regresa un carácter por renglón\n",
    "for i in texto:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86aa0950",
   "metadata": {},
   "source": [
    "Existen algunas funciones propias de los *strings* que nos ayudarán para trabajar con textos, como:\n",
    "- **lower**, pone la cadena en minúsculas\n",
    "- **upper**, pone la cadena en mayúsculas\n",
    "- **title**, pone en mayúscula la primera letra de cada palabra de un enunciado\n",
    "- **replace**, para sustituir algún texto\n",
    "- **rfind**, encuentra dentro de una cadena dónde inicia un texto de nuestro interés\n",
    "- **rspilt**, separa un enunciado en palabras (*tokens*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13816e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mi villano favorito'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lower\n",
    "texto.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "403f6a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MI VILLANO FAVORITO'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upper\n",
    "texto.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a9b2438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mi Villano Favorito'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# title\n",
    "texto.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba0f854c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mi marciano faVorito'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace\n",
    "texto.replace(\"viLLano\", \"marciano\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18a5a4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rfind\n",
    "texto.rfind(\"panda\") # no está este string, entonces devuelve -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "877a0078-214e-4338-ad1a-67a42c65f2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rfind\n",
    "texto.rfind(\"viLLano\") # sí está este string, entonces devuelve >0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e046b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mi', 'villano', 'favorito']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split\n",
    "texto.lower().rsplit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f76034a",
   "metadata": {},
   "source": [
    "## 2. Preproceso de texto\n",
    "Usualmente la información en formato de texto se encuentra desordenada y sin estructura. Para poder realizar un mejor análisis es importante \"normai\" esta información.\n",
    "\n",
    "Existen distintas herramientas para el preproceso de datos que podemos utilizar para obtener una base de datos limpia, entre las que se encuentran: utilizar letras minúscula, separa un enunciado en *tokens*, lematización (usar la raíz de la palabra), remover puntuación y *stopwords*, entre otras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d51d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import snscrape.modules.twitter as sntwitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02600374",
   "metadata": {},
   "source": [
    "### Base de datos inicial (raw)\n",
    "En este caso se consultaron 1,000 tweets con el hashtag #ElINENoSeToca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c51c5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: DeprecatedFeatureWarning: content is deprecated, use rawContent instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 176 ms, sys: 17 ms, total: 193 ms\n",
      "Wall time: 6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Parámetros\n",
    "tweets_list_ine = []\n",
    "maxTweets_ine = 100\n",
    "date_initial = \"2023-03-01\"\n",
    "\n",
    "# Get tweets\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('#ElINENoSeToca').get_items()): # se puede añadir esto --> since:'+date_initial\n",
    "        if i>maxTweets_ine-1:\n",
    "            break\n",
    "        tweets_list_ine.append([tweet.user.username, tweet.date, tweet.content])\n",
    "        \n",
    "# Pandas dataframe con tweets que mencionen el hashtag #ElINENoSeToca\n",
    "column_names = (\"username\",\"date\",\"tweet\")\n",
    "df = pd.DataFrame(tweets_list_ine, columns=column_names)\n",
    "# df['day'] = df['date'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5d1fc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>luisrojashernan</td>\n",
       "      <td>2023-04-08 05:14:51+00:00</td>\n",
       "      <td>Lo qué acabó de ver compañeros, un comercial d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rmartin_ernesto</td>\n",
       "      <td>2023-04-08 05:05:10+00:00</td>\n",
       "      <td>@PedroFerriz #ElIneNoSeToca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TLACAEL17552681</td>\n",
       "      <td>2023-04-08 04:41:40+00:00</td>\n",
       "      <td>@ferbelaunzaran @MexicoHablaMx #ElIneNoSeToca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gato525</td>\n",
       "      <td>2023-04-08 04:41:17+00:00</td>\n",
       "      <td>Rositas fresitas #ElIneNoSeToca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XosseTrinidad</td>\n",
       "      <td>2023-04-08 04:40:17+00:00</td>\n",
       "      <td>Hasta el lunes 3 de abril #ElIneNoSeToca y tre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>elmonsibais</td>\n",
       "      <td>2023-04-07 05:19:09+00:00</td>\n",
       "      <td>@PedroFerriz Mi Pedrito, recuerde el #ElINENoS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>elmonsibais</td>\n",
       "      <td>2023-04-07 04:59:26+00:00</td>\n",
       "      <td>@PagesBeatriz #ElINENoSeToca ud y su lacayo de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>VctorHu24702041</td>\n",
       "      <td>2023-04-07 04:44:20+00:00</td>\n",
       "      <td>La #DerechaMiserableyCorrupta solo escupe para...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Efren19501</td>\n",
       "      <td>2023-04-07 04:38:09+00:00</td>\n",
       "      <td>@_VicenteSerrano @lorenzocordovav De aquí en a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>josericardozac</td>\n",
       "      <td>2023-04-07 04:30:31+00:00</td>\n",
       "      <td>@analucia_medina Totalmente de acuerdo contigo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           username                      date  \\\n",
       "0   luisrojashernan 2023-04-08 05:14:51+00:00   \n",
       "1   rmartin_ernesto 2023-04-08 05:05:10+00:00   \n",
       "2   TLACAEL17552681 2023-04-08 04:41:40+00:00   \n",
       "3           gato525 2023-04-08 04:41:17+00:00   \n",
       "4     XosseTrinidad 2023-04-08 04:40:17+00:00   \n",
       "..              ...                       ...   \n",
       "95      elmonsibais 2023-04-07 05:19:09+00:00   \n",
       "96      elmonsibais 2023-04-07 04:59:26+00:00   \n",
       "97  VctorHu24702041 2023-04-07 04:44:20+00:00   \n",
       "98       Efren19501 2023-04-07 04:38:09+00:00   \n",
       "99   josericardozac 2023-04-07 04:30:31+00:00   \n",
       "\n",
       "                                                tweet  \n",
       "0   Lo qué acabó de ver compañeros, un comercial d...  \n",
       "1                         @PedroFerriz #ElIneNoSeToca  \n",
       "2       @ferbelaunzaran @MexicoHablaMx #ElIneNoSeToca  \n",
       "3                     Rositas fresitas #ElIneNoSeToca  \n",
       "4   Hasta el lunes 3 de abril #ElIneNoSeToca y tre...  \n",
       "..                                                ...  \n",
       "95  @PedroFerriz Mi Pedrito, recuerde el #ElINENoS...  \n",
       "96  @PagesBeatriz #ElINENoSeToca ud y su lacayo de...  \n",
       "97  La #DerechaMiserableyCorrupta solo escupe para...  \n",
       "98  @_VicenteSerrano @lorenzocordovav De aquí en a...  \n",
       "99  @analucia_medina Totalmente de acuerdo contigo...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# así se ve la base de datos\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dad92cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fs/sshbhn_57gv4s9wnsggc69_00000gn/T/ipykernel_38205/2951990929.py:2: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "  df.describe()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>KellerLore</td>\n",
       "      <td>2023-04-08 05:14:51+00:00</td>\n",
       "      <td>@PagesBeatriz @lopezobrador_ @ferbelaunzaran @...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-04-07 04:30:31+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-04-08 05:14:51+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                       date  \\\n",
       "count          100                        100   \n",
       "unique          83                        100   \n",
       "top     KellerLore  2023-04-08 05:14:51+00:00   \n",
       "freq             5                          1   \n",
       "first          NaN  2023-04-07 04:30:31+00:00   \n",
       "last           NaN  2023-04-08 05:14:51+00:00   \n",
       "\n",
       "                                                    tweet  \n",
       "count                                                 100  \n",
       "unique                                                 98  \n",
       "top     @PagesBeatriz @lopezobrador_ @ferbelaunzaran @...  \n",
       "freq                                                    2  \n",
       "first                                                 NaN  \n",
       "last                                                  NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# descripción general de los datos\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6df77e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username     83\n",
       "date        100\n",
       "tweet        98\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identificación de valores únicos por variable\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695c9a6b",
   "metadata": {},
   "source": [
    "### Eliminar signos de puntuación\n",
    "Aquí se eliminan los signos de puntuación con excepción de `#` y `@` para poder identificar los hashtags y las cuentas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b152a954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#library that contains punctuation\n",
    "import string\n",
    "signos_puntuacion = string.punctuation\n",
    "signos_puntuacion = signos_puntuacion.replace(\"#\", \"\")  # quitar '#' de hashtags \n",
    "signos_puntuacion = signos_puntuacion.replace(\"@\", \"\")  # quitar '@' de cuentas\n",
    "signos_puntuacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c5dbf46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>luisrojashernan</td>\n",
       "      <td>2023-04-08 05:14:51+00:00</td>\n",
       "      <td>Lo qué acabó de ver compañeros, un comercial d...</td>\n",
       "      <td>Lo qué acabó de ver compañeros un comercial de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rmartin_ernesto</td>\n",
       "      <td>2023-04-08 05:05:10+00:00</td>\n",
       "      <td>@PedroFerriz #ElIneNoSeToca</td>\n",
       "      <td>@PedroFerriz #ElIneNoSeToca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TLACAEL17552681</td>\n",
       "      <td>2023-04-08 04:41:40+00:00</td>\n",
       "      <td>@ferbelaunzaran @MexicoHablaMx #ElIneNoSeToca</td>\n",
       "      <td>@ferbelaunzaran @MexicoHablaMx #ElIneNoSeToca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gato525</td>\n",
       "      <td>2023-04-08 04:41:17+00:00</td>\n",
       "      <td>Rositas fresitas #ElIneNoSeToca</td>\n",
       "      <td>Rositas fresitas #ElIneNoSeToca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XosseTrinidad</td>\n",
       "      <td>2023-04-08 04:40:17+00:00</td>\n",
       "      <td>Hasta el lunes 3 de abril #ElIneNoSeToca y tre...</td>\n",
       "      <td>Hasta el lunes 3 de abril #ElIneNoSeToca y tre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                      date  \\\n",
       "0  luisrojashernan 2023-04-08 05:14:51+00:00   \n",
       "1  rmartin_ernesto 2023-04-08 05:05:10+00:00   \n",
       "2  TLACAEL17552681 2023-04-08 04:41:40+00:00   \n",
       "3          gato525 2023-04-08 04:41:17+00:00   \n",
       "4    XosseTrinidad 2023-04-08 04:40:17+00:00   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  Lo qué acabó de ver compañeros, un comercial d...   \n",
       "1                        @PedroFerriz #ElIneNoSeToca   \n",
       "2      @ferbelaunzaran @MexicoHablaMx #ElIneNoSeToca   \n",
       "3                    Rositas fresitas #ElIneNoSeToca   \n",
       "4  Hasta el lunes 3 de abril #ElIneNoSeToca y tre...   \n",
       "\n",
       "                                         tweet_clean  \n",
       "0  Lo qué acabó de ver compañeros un comercial de...  \n",
       "1                        @PedroFerriz #ElIneNoSeToca  \n",
       "2      @ferbelaunzaran @MexicoHablaMx #ElIneNoSeToca  \n",
       "3                    Rositas fresitas #ElIneNoSeToca  \n",
       "4  Hasta el lunes 3 de abril #ElIneNoSeToca y tre...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining the function to remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in signos_puntuacion])\n",
    "    return punctuationfree\n",
    "\n",
    "#storing the puntuation free text\n",
    "df['tweet_clean'] = df['tweet'].apply(lambda x:remove_punctuation(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418e3b65",
   "metadata": {},
   "source": [
    "### Textos en minúsculas\n",
    "Parte de la normalización es poner todos los textos en minúsculas (o mayúsculas), esto puede servir posteriormente por ejemplo para hacer un conteo de palabras.\n",
    "\n",
    "⚠️ _**Nota**: Al hacer esto existe el riesgo que se pierda información contextual; por ejemplo, dentro de un tweet cuando alguien escribe una palabra específica en mayúsculas y las demás en minúsculas esto conlleva un mayor importancia o aumento en tono de voz._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c210b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>luisrojashernan</td>\n",
       "      <td>2023-04-08 05:14:51+00:00</td>\n",
       "      <td>Lo qué acabó de ver compañeros, un comercial d...</td>\n",
       "      <td>lo qué acabó de ver compañeros un comercial de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rmartin_ernesto</td>\n",
       "      <td>2023-04-08 05:05:10+00:00</td>\n",
       "      <td>@PedroFerriz #ElIneNoSeToca</td>\n",
       "      <td>@pedroferriz #elinenosetoca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TLACAEL17552681</td>\n",
       "      <td>2023-04-08 04:41:40+00:00</td>\n",
       "      <td>@ferbelaunzaran @MexicoHablaMx #ElIneNoSeToca</td>\n",
       "      <td>@ferbelaunzaran @mexicohablamx #elinenosetoca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gato525</td>\n",
       "      <td>2023-04-08 04:41:17+00:00</td>\n",
       "      <td>Rositas fresitas #ElIneNoSeToca</td>\n",
       "      <td>rositas fresitas #elinenosetoca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XosseTrinidad</td>\n",
       "      <td>2023-04-08 04:40:17+00:00</td>\n",
       "      <td>Hasta el lunes 3 de abril #ElIneNoSeToca y tre...</td>\n",
       "      <td>hasta el lunes 3 de abril #elinenosetoca y tre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                      date  \\\n",
       "0  luisrojashernan 2023-04-08 05:14:51+00:00   \n",
       "1  rmartin_ernesto 2023-04-08 05:05:10+00:00   \n",
       "2  TLACAEL17552681 2023-04-08 04:41:40+00:00   \n",
       "3          gato525 2023-04-08 04:41:17+00:00   \n",
       "4    XosseTrinidad 2023-04-08 04:40:17+00:00   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  Lo qué acabó de ver compañeros, un comercial d...   \n",
       "1                        @PedroFerriz #ElIneNoSeToca   \n",
       "2      @ferbelaunzaran @MexicoHablaMx #ElIneNoSeToca   \n",
       "3                    Rositas fresitas #ElIneNoSeToca   \n",
       "4  Hasta el lunes 3 de abril #ElIneNoSeToca y tre...   \n",
       "\n",
       "                                         tweet_clean  \n",
       "0  lo qué acabó de ver compañeros un comercial de...  \n",
       "1                        @pedroferriz #elinenosetoca  \n",
       "2      @ferbelaunzaran @mexicohablamx #elinenosetoca  \n",
       "3                    rositas fresitas #elinenosetoca  \n",
       "4  hasta el lunes 3 de abril #elinenosetoca y tre...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cambiar los tweets a letras minúsculas\n",
    "df['tweet_clean'] = df['tweet_clean'].apply((lambda x: x.lower()))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45869e14",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "Aquí veremos cómo separar los enunciados (*tweets*) en *tokens* (palabras o cadenas de caracteres)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e1820a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>luisrojashernan</td>\n",
       "      <td>2023-04-08 05:14:51+00:00</td>\n",
       "      <td>Lo qué acabó de ver compañeros, un comercial d...</td>\n",
       "      <td>[lo, qué, acabó, de, ver, compañeros, un, come...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rmartin_ernesto</td>\n",
       "      <td>2023-04-08 05:05:10+00:00</td>\n",
       "      <td>@PedroFerriz #ElIneNoSeToca</td>\n",
       "      <td>[@pedroferriz, #elinenosetoca]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TLACAEL17552681</td>\n",
       "      <td>2023-04-08 04:41:40+00:00</td>\n",
       "      <td>@ferbelaunzaran @MexicoHablaMx #ElIneNoSeToca</td>\n",
       "      <td>[@ferbelaunzaran, @mexicohablamx, #elinenosetoca]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gato525</td>\n",
       "      <td>2023-04-08 04:41:17+00:00</td>\n",
       "      <td>Rositas fresitas #ElIneNoSeToca</td>\n",
       "      <td>[rositas, fresitas, #elinenosetoca]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XosseTrinidad</td>\n",
       "      <td>2023-04-08 04:40:17+00:00</td>\n",
       "      <td>Hasta el lunes 3 de abril #ElIneNoSeToca y tre...</td>\n",
       "      <td>[hasta, el, lunes, 3, de, abril, #elinenosetoc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                      date  \\\n",
       "0  luisrojashernan 2023-04-08 05:14:51+00:00   \n",
       "1  rmartin_ernesto 2023-04-08 05:05:10+00:00   \n",
       "2  TLACAEL17552681 2023-04-08 04:41:40+00:00   \n",
       "3          gato525 2023-04-08 04:41:17+00:00   \n",
       "4    XosseTrinidad 2023-04-08 04:40:17+00:00   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  Lo qué acabó de ver compañeros, un comercial d...   \n",
       "1                        @PedroFerriz #ElIneNoSeToca   \n",
       "2      @ferbelaunzaran @MexicoHablaMx #ElIneNoSeToca   \n",
       "3                    Rositas fresitas #ElIneNoSeToca   \n",
       "4  Hasta el lunes 3 de abril #ElIneNoSeToca y tre...   \n",
       "\n",
       "                                         tweet_clean  \n",
       "0  [lo, qué, acabó, de, ver, compañeros, un, come...  \n",
       "1                     [@pedroferriz, #elinenosetoca]  \n",
       "2  [@ferbelaunzaran, @mexicohablamx, #elinenosetoca]  \n",
       "3                [rositas, fresitas, #elinenosetoca]  \n",
       "4  [hasta, el, lunes, 3, de, abril, #elinenosetoc...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the tokens per tweet\n",
    "df['tweet_clean'] = df['tweet_clean'].apply(lambda x: x.rsplit())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487978ad",
   "metadata": {},
   "source": [
    "### Eliminar *stopwords*\n",
    "Las *stopwords* son palabras de uso común que no añaden un valor adicional al análisis de texto o que no tienen sentido, por lo que pueden ser eliminadas de nuestra lista de tokens.\n",
    "\n",
    "Existen distintas maneras de obtener la lista de stopwords:  \n",
    "> (1) Crear nuestra propia lista  \n",
    "\n",
    "> (2) Buscar alguna base de datos que contenga la lista de stopwords\n",
    "> - En GitHub encontré una lista de stopwords el el repositorio [Alir3z4/stop-words](https://github.com/Alir3z4/stop-words/blob/master/spanish.txt)\n",
    "> - Una alternativa es una lista de Kaggle [Spanish Stopwords W2V](https://www.kaggle.com/code/mpwolke/spanish-stopwords-w2v)\n",
    "> - Otra alternativa es la lista que da la página [countwordsfree.com](https://countwordsfree.com/stopwords/spanish)\n",
    "\n",
    "> (3) Algo más estandarizado y completo es utilizar la librería de *Natural Language Toolkit* (**NLTK**), la cual tiene listas de *stopwords* en distintos idiomas, donde (además de inglés) podemos encontrar la lista de palabras en español. Para instalar este paquete así como mayor detalle de uso, revisa la página de la [librería NLTK](https://www.nltk.org/data.html).\n",
    "\n",
    "⚠️ _**Nota**: antes de usar alguna de las opciones anteriores deberás de pensar cuál lista de stopwords se acopla mejor a tus necesidades!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e118462c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de stopwords en mi lista (1): 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a', 'ante', 'bajo', 'con', 'no', 'de', 'del', 'al', 'tras', 'bitcoin']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (1) Crear nuestra propia lista de stopwords\n",
    "stopwords_1 = ['a','ante','bajo','con','no','de','del','al','tras','bitcoin']\n",
    "\n",
    "print(\"Número de stopwords en mi lista (1):\", len(stopwords_1))\n",
    "stopwords_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a957d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de stopwords en mi lista (2): 609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'actualmente',\n",
       " 'adelante',\n",
       " 'además',\n",
       " 'afirmó',\n",
       " 'agregó',\n",
       " 'ahora',\n",
       " 'ahí',\n",
       " 'al',\n",
       " 'algo',\n",
       " 'alguna',\n",
       " 'algunas',\n",
       " 'alguno',\n",
       " 'algunos',\n",
       " 'algún']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (2) Buscar alguna base de datos que contenga la lista de stopwords.\n",
    "#     En este ejemplo bajamos la lista de GitHub\n",
    "import urllib3\n",
    "\n",
    "http = urllib3.PoolManager()\n",
    "r = http.request('GET', \"https://raw.githubusercontent.com/Alir3z4/stop-words/master/spanish.txt\")\n",
    "stopwords_2 = r.data.decode('utf-8').replace(\"\\n\",\" \").rsplit()\n",
    "\n",
    "print(\"Número de stopwords en mi lista (2):\", len(stopwords_2))\n",
    "stopwords_2[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff24eac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de stopwords en de NLTK library (3): 313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['de',\n",
       " 'la',\n",
       " 'que',\n",
       " 'el',\n",
       " 'en',\n",
       " 'y',\n",
       " 'a',\n",
       " 'los',\n",
       " 'del',\n",
       " 'se',\n",
       " 'las',\n",
       " 'por',\n",
       " 'un',\n",
       " 'para',\n",
       " 'con']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (3) Uso de NLP Toolkit library\n",
    "\n",
    "## Para instalar la librería revisa la página: https://www.nltk.org/data.html\n",
    "## Nota, este proceso puede ser tardado...\n",
    "# !pip install nltk\n",
    "# nltk.download()\n",
    "\n",
    "# load library\n",
    "import nltk\n",
    "\n",
    "stopwords_3 = nltk.corpus.stopwords.words('spanish')\n",
    "\n",
    "print(\"Número de stopwords en de NLTK library (3):\", len(stopwords_3))\n",
    "stopwords_3[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a12868e",
   "metadata": {},
   "source": [
    "**Vamos a eliminar las stopwords usando la lista que obtivimos de NLTK library (opción 3):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "226d0c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>luisrojashernan</td>\n",
       "      <td>2023-04-08 05:14:51+00:00</td>\n",
       "      <td>Lo qué acabó de ver compañeros, un comercial d...</td>\n",
       "      <td>[acabó, ver, compañeros, comercial, pri, cuyas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rmartin_ernesto</td>\n",
       "      <td>2023-04-08 05:05:10+00:00</td>\n",
       "      <td>@PedroFerriz #ElIneNoSeToca</td>\n",
       "      <td>[@pedroferriz, #elinenosetoca]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TLACAEL17552681</td>\n",
       "      <td>2023-04-08 04:41:40+00:00</td>\n",
       "      <td>@ferbelaunzaran @MexicoHablaMx #ElIneNoSeToca</td>\n",
       "      <td>[@ferbelaunzaran, @mexicohablamx, #elinenosetoca]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gato525</td>\n",
       "      <td>2023-04-08 04:41:17+00:00</td>\n",
       "      <td>Rositas fresitas #ElIneNoSeToca</td>\n",
       "      <td>[rositas, fresitas, #elinenosetoca]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XosseTrinidad</td>\n",
       "      <td>2023-04-08 04:40:17+00:00</td>\n",
       "      <td>Hasta el lunes 3 de abril #ElIneNoSeToca y tre...</td>\n",
       "      <td>[lunes, 3, abril, #elinenosetoca, tres, mapach...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                      date  \\\n",
       "0  luisrojashernan 2023-04-08 05:14:51+00:00   \n",
       "1  rmartin_ernesto 2023-04-08 05:05:10+00:00   \n",
       "2  TLACAEL17552681 2023-04-08 04:41:40+00:00   \n",
       "3          gato525 2023-04-08 04:41:17+00:00   \n",
       "4    XosseTrinidad 2023-04-08 04:40:17+00:00   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  Lo qué acabó de ver compañeros, un comercial d...   \n",
       "1                        @PedroFerriz #ElIneNoSeToca   \n",
       "2      @ferbelaunzaran @MexicoHablaMx #ElIneNoSeToca   \n",
       "3                    Rositas fresitas #ElIneNoSeToca   \n",
       "4  Hasta el lunes 3 de abril #ElIneNoSeToca y tre...   \n",
       "\n",
       "                                         tweet_clean  \n",
       "0  [acabó, ver, compañeros, comercial, pri, cuyas...  \n",
       "1                     [@pedroferriz, #elinenosetoca]  \n",
       "2  [@ferbelaunzaran, @mexicohablamx, #elinenosetoca]  \n",
       "3                [rositas, fresitas, #elinenosetoca]  \n",
       "4  [lunes, 3, abril, #elinenosetoca, tres, mapach...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining the function to remove stopwords from tokenized text\n",
    "def remove_stopwords(text):\n",
    "    output= [i for i in text if i not in stopwords_3]\n",
    "    return output\n",
    "\n",
    "#applying the stopwords function to thet tweets\n",
    "df['tweet_clean'] = df['tweet_clean'].apply(lambda x:remove_stopwords(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c644c42f",
   "metadata": {},
   "source": [
    "### Lematización\n",
    "Este paso nos servirá para extraer la la raíz de las palabras, para poder \"normalizar\" el texto y realizar un mejor análisis. Aquí nuevamente utilizaremos la librería `NLTK`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0c6116f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>luisrojashernan</td>\n",
       "      <td>2023-04-08 05:14:51+00:00</td>\n",
       "      <td>Lo qué acabó de ver compañeros, un comercial d...</td>\n",
       "      <td>[acabó, ver, compañeros, comercial, pri, cuyas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rmartin_ernesto</td>\n",
       "      <td>2023-04-08 05:05:10+00:00</td>\n",
       "      <td>@PedroFerriz #ElIneNoSeToca</td>\n",
       "      <td>[@pedroferriz, #elinenosetoca]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TLACAEL17552681</td>\n",
       "      <td>2023-04-08 04:41:40+00:00</td>\n",
       "      <td>@ferbelaunzaran @MexicoHablaMx #ElIneNoSeToca</td>\n",
       "      <td>[@ferbelaunzaran, @mexicohablamx, #elinenosetoca]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gato525</td>\n",
       "      <td>2023-04-08 04:41:17+00:00</td>\n",
       "      <td>Rositas fresitas #ElIneNoSeToca</td>\n",
       "      <td>[rosita, fresitas, #elinenosetoca]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XosseTrinidad</td>\n",
       "      <td>2023-04-08 04:40:17+00:00</td>\n",
       "      <td>Hasta el lunes 3 de abril #ElIneNoSeToca y tre...</td>\n",
       "      <td>[lunes, 3, abril, #elinenosetoca, tres, mapach...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                      date  \\\n",
       "0  luisrojashernan 2023-04-08 05:14:51+00:00   \n",
       "1  rmartin_ernesto 2023-04-08 05:05:10+00:00   \n",
       "2  TLACAEL17552681 2023-04-08 04:41:40+00:00   \n",
       "3          gato525 2023-04-08 04:41:17+00:00   \n",
       "4    XosseTrinidad 2023-04-08 04:40:17+00:00   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  Lo qué acabó de ver compañeros, un comercial d...   \n",
       "1                        @PedroFerriz #ElIneNoSeToca   \n",
       "2      @ferbelaunzaran @MexicoHablaMx #ElIneNoSeToca   \n",
       "3                    Rositas fresitas #ElIneNoSeToca   \n",
       "4  Hasta el lunes 3 de abril #ElIneNoSeToca y tre...   \n",
       "\n",
       "                                         tweet_clean  \n",
       "0  [acabó, ver, compañeros, comercial, pri, cuyas...  \n",
       "1                     [@pedroferriz, #elinenosetoca]  \n",
       "2  [@ferbelaunzaran, @mexicohablamx, #elinenosetoca]  \n",
       "3                 [rosita, fresitas, #elinenosetoca]  \n",
       "4  [lunes, 3, abril, #elinenosetoca, tres, mapach...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining the object for Lemmatization\n",
    "wordnet_lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "#defining the function for lemmatization\n",
    "def lemmatizer(text):\n",
    "    lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
    "    return lemm_text\n",
    "\n",
    "#lemmatization of our tweets\n",
    "df['tweet_clean'] = df['tweet_clean'].apply(lambda x:lemmatizer(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830493b5",
   "metadata": {},
   "source": [
    "### Eliminar URLs\n",
    "En este caso, también eliminamos las URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46d04d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>luisrojashernan</td>\n",
       "      <td>2023-04-08 05:14:51+00:00</td>\n",
       "      <td>Lo qué acabó de ver compañeros, un comercial d...</td>\n",
       "      <td>[acabó, ver, compañeros, comercial, pri, cuyas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rmartin_ernesto</td>\n",
       "      <td>2023-04-08 05:05:10+00:00</td>\n",
       "      <td>@PedroFerriz #ElIneNoSeToca</td>\n",
       "      <td>[@pedroferriz, #elinenosetoca]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TLACAEL17552681</td>\n",
       "      <td>2023-04-08 04:41:40+00:00</td>\n",
       "      <td>@ferbelaunzaran @MexicoHablaMx #ElIneNoSeToca</td>\n",
       "      <td>[@ferbelaunzaran, @mexicohablamx, #elinenosetoca]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gato525</td>\n",
       "      <td>2023-04-08 04:41:17+00:00</td>\n",
       "      <td>Rositas fresitas #ElIneNoSeToca</td>\n",
       "      <td>[rosita, fresitas, #elinenosetoca]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XosseTrinidad</td>\n",
       "      <td>2023-04-08 04:40:17+00:00</td>\n",
       "      <td>Hasta el lunes 3 de abril #ElIneNoSeToca y tre...</td>\n",
       "      <td>[lunes, 3, abril, #elinenosetoca, tres, mapach...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                      date  \\\n",
       "0  luisrojashernan 2023-04-08 05:14:51+00:00   \n",
       "1  rmartin_ernesto 2023-04-08 05:05:10+00:00   \n",
       "2  TLACAEL17552681 2023-04-08 04:41:40+00:00   \n",
       "3          gato525 2023-04-08 04:41:17+00:00   \n",
       "4    XosseTrinidad 2023-04-08 04:40:17+00:00   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  Lo qué acabó de ver compañeros, un comercial d...   \n",
       "1                        @PedroFerriz #ElIneNoSeToca   \n",
       "2      @ferbelaunzaran @MexicoHablaMx #ElIneNoSeToca   \n",
       "3                    Rositas fresitas #ElIneNoSeToca   \n",
       "4  Hasta el lunes 3 de abril #ElIneNoSeToca y tre...   \n",
       "\n",
       "                                         tweet_clean  \n",
       "0  [acabó, ver, compañeros, comercial, pri, cuyas...  \n",
       "1                     [@pedroferriz, #elinenosetoca]  \n",
       "2  [@ferbelaunzaran, @mexicohablamx, #elinenosetoca]  \n",
       "3                 [rosita, fresitas, #elinenosetoca]  \n",
       "4  [lunes, 3, abril, #elinenosetoca, tres, mapach...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def erase_urls(text):\n",
    "    output = [i for i in text if i.rfind(\"http\")==-1]\n",
    "    return output\n",
    "\n",
    "# texto.rfind(\"villano\")\n",
    "df['tweet_clean'] = df['tweet_clean'].apply(lambda x:erase_urls(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb7e003",
   "metadata": {},
   "source": [
    "### Resultado final de preproceso (BD final)\n",
    "A continuación se muestran los textos iniciales en la columna \"tweets\", y la información preprocesada en la columna \"tweet_clean\", a manera de comparación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "691f5e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lo qué acabó de ver compañeros, un comercial d...</td>\n",
       "      <td>[acabó, ver, compañeros, comercial, pri, cuyas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@PedroFerriz #ElIneNoSeToca</td>\n",
       "      <td>[@pedroferriz, #elinenosetoca]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@ferbelaunzaran @MexicoHablaMx #ElIneNoSeToca</td>\n",
       "      <td>[@ferbelaunzaran, @mexicohablamx, #elinenosetoca]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rositas fresitas #ElIneNoSeToca</td>\n",
       "      <td>[rosita, fresitas, #elinenosetoca]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hasta el lunes 3 de abril #ElIneNoSeToca y tre...</td>\n",
       "      <td>[lunes, 3, abril, #elinenosetoca, tres, mapach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>@PedroFerriz Mi Pedrito, recuerde el #ElINENoS...</td>\n",
       "      <td>[@pedroferriz, pedrito, recuerde, #elinenosetoca]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>@PagesBeatriz #ElINENoSeToca ud y su lacayo de...</td>\n",
       "      <td>[@pagesbeatriz, #elinenosetoca, ud, lacayo, at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>La #DerechaMiserableyCorrupta solo escupe para...</td>\n",
       "      <td>[#derechamiserableycorrupta, solo, escupe, arr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>@_VicenteSerrano @lorenzocordovav De aquí en a...</td>\n",
       "      <td>[@vicenteserrano, @lorenzocordovav, aquí, adel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>@analucia_medina Totalmente de acuerdo contigo...</td>\n",
       "      <td>[@analuciamedina, totalmente, acuerdo, contigo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet  \\\n",
       "0   Lo qué acabó de ver compañeros, un comercial d...   \n",
       "1                         @PedroFerriz #ElIneNoSeToca   \n",
       "2       @ferbelaunzaran @MexicoHablaMx #ElIneNoSeToca   \n",
       "3                     Rositas fresitas #ElIneNoSeToca   \n",
       "4   Hasta el lunes 3 de abril #ElIneNoSeToca y tre...   \n",
       "..                                                ...   \n",
       "95  @PedroFerriz Mi Pedrito, recuerde el #ElINENoS...   \n",
       "96  @PagesBeatriz #ElINENoSeToca ud y su lacayo de...   \n",
       "97  La #DerechaMiserableyCorrupta solo escupe para...   \n",
       "98  @_VicenteSerrano @lorenzocordovav De aquí en a...   \n",
       "99  @analucia_medina Totalmente de acuerdo contigo...   \n",
       "\n",
       "                                          tweet_clean  \n",
       "0   [acabó, ver, compañeros, comercial, pri, cuyas...  \n",
       "1                      [@pedroferriz, #elinenosetoca]  \n",
       "2   [@ferbelaunzaran, @mexicohablamx, #elinenosetoca]  \n",
       "3                  [rosita, fresitas, #elinenosetoca]  \n",
       "4   [lunes, 3, abril, #elinenosetoca, tres, mapach...  \n",
       "..                                                ...  \n",
       "95  [@pedroferriz, pedrito, recuerde, #elinenosetoca]  \n",
       "96  [@pagesbeatriz, #elinenosetoca, ud, lacayo, at...  \n",
       "97  [#derechamiserableycorrupta, solo, escupe, arr...  \n",
       "98  [@vicenteserrano, @lorenzocordovav, aquí, adel...  \n",
       "99  [@analuciamedina, totalmente, acuerdo, contigo...  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['tweet', 'tweet_clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b122a751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo de tweet...\n",
      "- original tweet:\n",
      " @ferbelaunzaran @lopezobrador_ Que metida de reata les volvió a hacer @lopezobrador_ \n",
      "#ElIneNoSeToca https://t.co/hVPWVs8vHQ \n",
      "\n",
      "- tweet clean:\n",
      " ['@ferbelaunzaran', '@lopezobrador', 'metida', 'reata', 'volvió', 'hacer', '@lopezobrador', '#elinenosetoca']\n"
     ]
    }
   ],
   "source": [
    "print(\"Ejemplo de tweet...\\n- original tweet:\\n\",df['tweet'][50],\n",
    "      \"\\n\\n- tweet clean:\\n\", df['tweet_clean'][50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703b4d71",
   "metadata": {},
   "source": [
    "## 3. Regular expressions (*Regex*)\n",
    "Las expresiones regulares mejor conocidas como *regex* son una herramienta que nos sirve para trabajar con texto, con el cual se pueden realizar distintas operaciones como búsqueda o reemplazo de un texto específico.\n",
    "\n",
    "Existen distintos operadores que se utilizan en *regex*, estos son los que utilizaremos para nuestros ejemplos. \n",
    "\n",
    "\n",
    "|Operador|Descripción (_en inglés_)|\n",
    "|:------:|:----------------------|\n",
    "|. (punto)|In the default mode, this matches any character except a newline. If the DOTALL flag has been specified, this matches any character including a newline.|\n",
    "|* (asterisco) |Causes the resulting RE to match 0 or more repetitions of the preceding RE, as many repetitions as are possible. ab* will match ‘a’, ‘ab’, or ‘a’ followed by any number of ‘b’s.|\n",
    "|+ (más) |Causes the resulting RE to match 1 or more repetitions of the preceding RE. ab+ will match ‘a’ followed by any non-zero number of ‘b’s; it will not match just ‘a’.|\n",
    "|[ ]| Used to indicate a set of characters. In a set:<ul><li>Characters can be listed individually, e.g. [amk] will match 'a', 'm', or 'k'.</li><li>Ranges of characters can be indicated by giving two characters and separating them by a '-', for example [a-z] will match any lowercase ASCII letter, [0-5][0-9] will match all the two-digits numbers from 00 to 59, and [0-9A-Fa-f] will match any hexadecimal digit. If - is escaped (e.g. [a\\-z]) or if it’s placed as the first or last character (e.g. [-a] or [a-]), it will match a literal '-'.</li><li>Special characters lose their special meaning inside sets. For example, [(+*)] will match any of the literal characters '(', '+', '*', or ')'.</li></ul>|\n",
    "|\\n |line break|\n",
    "|\\s|space|\n",
    "\n",
    "⚠️ Se recomienda ampliamente que revisen la página de la [librería **`re`** - *Regular expression operations*](https://docs.python.org/3/library/re.html) para identificar todos los operadores, documentación y ejemplos de como utilizar _regex_.\n",
    "\n",
    "📌 Si les interesa practicar el uso de _regex_, les recomiendo la página de [regexr.com](https://regexr.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "713d8697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load regex library\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d72ddd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracto de canción \"El amor\" de Arjona, link: https://www.letras.com/arjona-ricardo/1963651/\n",
    "texto = \"\"\"El amor tiene firma de autor\n",
    "En las causas pérdidas\n",
    "El amor siempre empieza soñando\n",
    "Y termina en insomnio\n",
    "Es un acto profundo de fe\n",
    "Que huele a mentira\n",
    "El amor baila al son que le toquen\n",
    "Sea Dios o el demonio\n",
    "Sea Dios o el demonio\n",
    "\n",
    "El amor es la guerra pérdida\n",
    "Entre el sexo y la risa\n",
    "Es la llave con que abres\n",
    "El grifo del agua en los ojos\n",
    "Es el tiempo más lento del mundo\n",
    "Cuando va de prisa\n",
    "El amor se abre paso despacio\n",
    "No importa el cerrojo\n",
    "\n",
    "El amor es la arrogancia\n",
    "De aferrarse a lo imposible\n",
    "Es buscar en otra parte\n",
    "Lo que no encuentras en ti\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dc6c9e",
   "metadata": {},
   "source": [
    "### Encontrar un texto usando _regex_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b70a9afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['El amor tiene firma de autor',\n",
       " 'El amor siempre empieza soñando',\n",
       " 'El amor baila al son que le toquen',\n",
       " 'El amor es la guerra pérdida',\n",
       " 'El amor se abre paso despacio',\n",
       " 'El amor es la arrogancia']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encontrar todos los enunciados que tengan la palabra 'amor'\n",
    "re.findall(r'.*[Aa]mor.*', texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc46c2d",
   "metadata": {},
   "source": [
    "#### Sustituir una palabra, frase o cadena de caracterés por otro texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b73b6a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El Guacamole tiene firma de autor. En las causas pérdidas. El Guacamole siempre empieza soñando. Y termina en insomnio. Es un acto profundo de fe. Que huele a mentira. El Guacamole baila al son que le toquen. Sea Dios o el demonio. Sea Dios o el demonio. El Guacamole es la guerra pérdida. Entre el sexo y la risa. Es la llave con que abres. El grifo del agua en los ojos. Es el tiempo más lento del mundo. Cuando va de prisa. El Guacamole se abre paso despacio. No importa el cerrojo. El Guacamole es la arrogancia. De aferrarse a lo imposible. Es buscar en otra parte. Lo que no encuentras en ti'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Substituir la palabra 'amor' por 'cepillo de dientes'\n",
    "texto_sub = re.sub('[A|a]mor', 'Guacamole', texto)  # cambia la palabra\n",
    "texto_sub = re.sub('\\n+', '. ', texto_sub)  # cambia el salto de dos renglones por un punto \n",
    "texto_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e3e986",
   "metadata": {},
   "source": [
    "### Dividir el texto en una lista de strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ac5f243-29fc-4bec-9d85-2fed5ada3202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El amor tiene firma de autor\\nEn las causas pérdidas\\nEl amor siempre empieza soñando\\nY termina en insomnio\\nEs un acto profundo de fe\\nQue huele a mentira\\nEl amor baila al son que le toquen\\nSea Dios o el demonio\\nSea Dios o el demonio\\n\\nEl amor es la guerra pérdida\\nEntre el sexo y la risa\\nEs la llave con que abres\\nEl grifo del agua en los ojos\\nEs el tiempo más lento del mundo\\nCuando va de prisa\\nEl amor se abre paso despacio\\nNo importa el cerrojo\\n\\nEl amor es la arrogancia\\nDe aferrarse a lo imposible\\nEs buscar en otra parte\\nLo que no encuentras en ti'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto # original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "74607e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['El amor tiene firma de autor',\n",
       " 'En las causas pérdidas',\n",
       " 'El amor siempre empieza soñando',\n",
       " 'Y termina en insomnio',\n",
       " 'Es un acto profundo de fe',\n",
       " 'Que huele a mentira',\n",
       " 'El amor baila al son que le toquen',\n",
       " 'Sea Dios o el demonio',\n",
       " 'Sea Dios o el demonio',\n",
       " 'El amor es la guerra pérdida',\n",
       " 'Entre el sexo y la risa',\n",
       " 'Es la llave con que abres',\n",
       " 'El grifo del agua en los ojos',\n",
       " 'Es el tiempo más lento del mundo',\n",
       " 'Cuando va de prisa',\n",
       " 'El amor se abre paso despacio',\n",
       " 'No importa el cerrojo',\n",
       " 'El amor es la arrogancia',\n",
       " 'De aferrarse a lo imposible',\n",
       " 'Es buscar en otra parte',\n",
       " 'Lo que no encuentras en ti']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(\"\\n+\", texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b5ba28",
   "metadata": {},
   "source": [
    "## 4. spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8e7ba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install spaCy webpage: https://spacy.io/usage\n",
    "# ! conda install -c conda-forge spacy  # <-install spaCy\n",
    "# ! python -m spacy download en_core_web_sm   # <-spaCy English pipeline optimized for CPU.\n",
    "# ! python -m spacy download es_core_news_sm  # <-spaCy Spanish pipeline optimized for CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9fa37727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load library\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31063b40",
   "metadata": {},
   "source": [
    "### Obtener características de cada *token*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d28304a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enunciado:\n",
      " Me llegó un email al correo leo234@gmail.com que dice: \"OMG! El señor Carlos rompió el controldel televisor hoy y tuve que comprar otro en www.amazon.com.mx\". \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>dep</th>\n",
       "      <th>is_email</th>\n",
       "      <th>is_url</th>\n",
       "      <th>next_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Me</td>\n",
       "      <td>yo</td>\n",
       "      <td>PRON</td>\n",
       "      <td>iobj</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>llegó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llegó</td>\n",
       "      <td>llegar</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>llegó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>un</td>\n",
       "      <td>uno</td>\n",
       "      <td>DET</td>\n",
       "      <td>det</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>email</td>\n",
       "      <td>email</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>llegó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>al</td>\n",
       "      <td>al</td>\n",
       "      <td>ADP</td>\n",
       "      <td>case</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>correo</td>\n",
       "      <td>correo</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>obl</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>llegó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>leo234@gmail.com</td>\n",
       "      <td>leo234@gmail.com</td>\n",
       "      <td>NUM</td>\n",
       "      <td>appos</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>correo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>que</td>\n",
       "      <td>que</td>\n",
       "      <td>PRON</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>dice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dice</td>\n",
       "      <td>decir</td>\n",
       "      <td>VERB</td>\n",
       "      <td>acl</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>OMG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"</td>\n",
       "      <td>\"</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>OMG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OMG</td>\n",
       "      <td>OMG</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>obj</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>dice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>OMG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>El</td>\n",
       "      <td>el</td>\n",
       "      <td>DET</td>\n",
       "      <td>det</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>señor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>señor</td>\n",
       "      <td>señor</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>rompió</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Carlos</td>\n",
       "      <td>Carlos</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>appos</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>señor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rompió</td>\n",
       "      <td>romper</td>\n",
       "      <td>VERB</td>\n",
       "      <td>acl</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>OMG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>el</td>\n",
       "      <td>el</td>\n",
       "      <td>DET</td>\n",
       "      <td>det</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>televisor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>controldel</td>\n",
       "      <td>controldel</td>\n",
       "      <td>ADV</td>\n",
       "      <td>case</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>el</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>televisor</td>\n",
       "      <td>televisor</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>obj</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>rompió</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>hoy</td>\n",
       "      <td>hoy</td>\n",
       "      <td>ADV</td>\n",
       "      <td>advmod</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>rompió</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>cc</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>tuve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tuve</td>\n",
       "      <td>tener</td>\n",
       "      <td>VERB</td>\n",
       "      <td>conj</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>rompió</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>que</td>\n",
       "      <td>que</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>cc</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>comprar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>comprar</td>\n",
       "      <td>comprar</td>\n",
       "      <td>VERB</td>\n",
       "      <td>conj</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>tuve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>otro</td>\n",
       "      <td>otro</td>\n",
       "      <td>PRON</td>\n",
       "      <td>obj</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>comprar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>ADP</td>\n",
       "      <td>case</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>www.amazon.com.mx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>www.amazon.com.mx</td>\n",
       "      <td>www.amazon.com.mx</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>obl</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>comprar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>\"</td>\n",
       "      <td>\"</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>OMG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>llegó</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 text              lemma    pos     dep  is_email  is_url  \\\n",
       "0                  Me                 yo   PRON    iobj     False   False   \n",
       "1               llegó             llegar   VERB    ROOT     False   False   \n",
       "2                  un                uno    DET     det     False   False   \n",
       "3               email              email   NOUN   nsubj     False   False   \n",
       "4                  al                 al    ADP    case     False   False   \n",
       "5              correo             correo   NOUN     obl     False   False   \n",
       "6    leo234@gmail.com   leo234@gmail.com    NUM   appos      True   False   \n",
       "7                 que                que   PRON   nsubj     False   False   \n",
       "8                dice              decir   VERB     acl     False   False   \n",
       "9                   :                  :  PUNCT   punct     False   False   \n",
       "10                  \"                  \"  PUNCT   punct     False   False   \n",
       "11                OMG                OMG  PROPN     obj     False   False   \n",
       "12                  !                  !  PUNCT   punct     False   False   \n",
       "13                 El                 el    DET     det     False   False   \n",
       "14              señor              señor   NOUN   nsubj     False   False   \n",
       "15             Carlos             Carlos  PROPN   appos     False   False   \n",
       "16             rompió             romper   VERB     acl     False   False   \n",
       "17                 el                 el    DET     det     False   False   \n",
       "18         controldel         controldel    ADV    case     False   False   \n",
       "19          televisor          televisor   NOUN     obj     False   False   \n",
       "20                hoy                hoy    ADV  advmod     False   False   \n",
       "21                  y                  y  CCONJ      cc     False   False   \n",
       "22               tuve              tener   VERB    conj     False   False   \n",
       "23                que                que  SCONJ      cc     False   False   \n",
       "24            comprar            comprar   VERB    conj     False   False   \n",
       "25               otro               otro   PRON     obj     False   False   \n",
       "26                 en                 en    ADP    case     False   False   \n",
       "27  www.amazon.com.mx  www.amazon.com.mx  PROPN     obl     False    True   \n",
       "28                  \"                  \"  PUNCT   punct     False   False   \n",
       "29                  .                  .  PUNCT   punct     False   False   \n",
       "\n",
       "            next_text  \n",
       "0               llegó  \n",
       "1               llegó  \n",
       "2               email  \n",
       "3               llegó  \n",
       "4              correo  \n",
       "5               llegó  \n",
       "6              correo  \n",
       "7                dice  \n",
       "8              correo  \n",
       "9                 OMG  \n",
       "10                OMG  \n",
       "11               dice  \n",
       "12                OMG  \n",
       "13              señor  \n",
       "14             rompió  \n",
       "15              señor  \n",
       "16                OMG  \n",
       "17          televisor  \n",
       "18                 el  \n",
       "19             rompió  \n",
       "20             rompió  \n",
       "21               tuve  \n",
       "22             rompió  \n",
       "23            comprar  \n",
       "24               tuve  \n",
       "25            comprar  \n",
       "26  www.amazon.com.mx  \n",
       "27            comprar  \n",
       "28                OMG  \n",
       "29              llegó  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load spaCy Spanish pipeline optimized\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "# ejemplo\n",
    "enunciado = 'Me llegó un email al correo leo234@gmail.com que dice: \"OMG! El señor Carlos rompió el control\\\n",
    "del televisor hoy y tuve que comprar otro en www.amazon.com.mx\".'\n",
    "\n",
    "# volver el enunciado un objeto tipo NLP\n",
    "doc = nlp(enunciado) #(sentences[0])\n",
    "print(\"Enunciado:\\n\",doc.text,\"\\n\")\n",
    "\n",
    "# Para cada token (palabra/cadena) se obtienen distintas características:\n",
    "# - texto\n",
    "# - tag con tipo de texto: noun, verb, determinant, adverb, conjunction\n",
    "# - dep: dependenxy\n",
    "# - like_email: identifica si el token es un email\n",
    "# - like_url: identifica si el token es una página web\n",
    "list_tokens = []\n",
    "for token in doc:\n",
    "    list_tokens.append([token.text,token.lemma_,token.pos_,token.dep_,token.like_email,\n",
    "                        token.like_url, token.head.text])\n",
    "\n",
    "# Revisar algunas de las características de cada token\n",
    "pd.DataFrame(list_tokens, columns=['text','lemma','pos','dep','is_email','is_url','next_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11c3e78",
   "metadata": {},
   "source": [
    "### Preproceso con spaCy\n",
    "Ejemplo de función para preproceso usando spaCy, Regex y métodos de strings, comparando resultados con el del preproceso que se vio al inicio de este Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b921e0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text,\n",
    "               min_token_len = 2,\n",
    "               irrelevant_pos = ['PRON', 'SPACE', 'PUNCT', 'ADV', 'ADP', 'CCONJ', 'AUX', 'PRP'],\n",
    "               avoid_entities = ['PERSON', 'ORG', 'LOC', 'GPE']):\n",
    "    # note: Didn't use the following options in the `preprocess_comments`\n",
    "    #    - 'PROPN', erase proper names, but also words as orange.\n",
    "    #    - 'DET', removes the word 'no', which changes the meaning.\n",
    "    \"\"\"\n",
    "    Function that identify sensible information, anonymize and transforms\n",
    "    the data in a useful format for using with tokens.\n",
    "    Parameters\n",
    "    -------------\n",
    "    text : (list)\n",
    "        the list of text to be preprocessed\n",
    "    irrelevant_pos : (list)\n",
    "        a list of irrelevant 'pos' tags\n",
    "    avoid_entities : (list)\n",
    "        a list of entity labels to be avoided\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    (list) list of preprocessed text\n",
    "\n",
    "    Example\n",
    "    -------------\n",
    "    example = [\"Hello, I'm George and I love swimming!\",\n",
    "                \"I am a really good cook; what about you?\",\n",
    "                \"Contact me at george23@gmail.com\"]\n",
    "    preprocess(example)\n",
    "    (output:) ['hello love swimming', 'good cook', 'contact']\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    others = [\"'s\", \"the\", \"that\", \"this\", \"to\", \"-PRON-\"]\n",
    "    # comment: \"-PRON-\" is a lemma for \"my\", \"your\", etc.\n",
    "\n",
    "    # function\n",
    "    for sent in text:\n",
    "        # <string methods>\n",
    "        sent = str(sent).lower()\n",
    "        \n",
    "        # <regex>\n",
    "        sent = re.sub(r\"(F|f)acebook\", \"redes sociales\", sent)\n",
    "        sent = re.sub(r\"(T|t)witter\", \"redes sociales\", sent)\n",
    "        sent = re.sub(r\"(I|i)nstagram\", \"redes sociales\", sent)\n",
    "        \n",
    "        result_sent = []\n",
    "        \n",
    "        # <spaCy>\n",
    "        doc = nlp(sent)\n",
    "        entities = [str(ent) for ent in doc.ents if ent.label_ in avoid_entities]\n",
    "                   # This helps to detect names of persons, organization and dates\n",
    "        for token in doc:            \n",
    "            if (token.like_email or\n",
    "                token.like_url or\n",
    "                token.pos_ in irrelevant_pos or\n",
    "                str(token) in entities or\n",
    "                str(token.lemma_) in others or\n",
    "                len(token) < min_token_len):\n",
    "                continue\n",
    "            else:\n",
    "                result_sent.append(token.lemma_)\n",
    "        result.append(result_sent)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c84ddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess tweets\n",
    "df['tweet_spacy_preprocess'] = preprocess(df['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a1849fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_clean</th>\n",
       "      <th>tweet_spacy_preprocess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lo qué acabó de ver compañeros, un comercial d...</td>\n",
       "      <td>[acabó, ver, compañeros, comercial, pri, cuyas...</td>\n",
       "      <td>[acabar, ver, compañero, uno, comercial, image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@PedroFerriz #ElIneNoSeToca</td>\n",
       "      <td>[@pedroferriz, #elinenosetoca]</td>\n",
       "      <td>[@pedroferriz]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@ferbelaunzaran @MexicoHablaMx #ElIneNoSeToca</td>\n",
       "      <td>[@ferbelaunzaran, @mexicohablamx, #elinenosetoca]</td>\n",
       "      <td>[@ferbelaunzar, @mexicohablamx]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rositas fresitas #ElIneNoSeToca</td>\n",
       "      <td>[rosita, fresitas, #elinenosetoca]</td>\n",
       "      <td>[rosita, fresita]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hasta el lunes 3 de abril #ElIneNoSeToca y tre...</td>\n",
       "      <td>[lunes, 3, abril, #elinenosetoca, tres, mapach...</td>\n",
       "      <td>[el, lunes, abril, elinenosetoca, tres, mapach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>@PedroFerriz Mi Pedrito, recuerde el #ElINENoS...</td>\n",
       "      <td>[@pedroferriz, pedrito, recuerde, #elinenosetoca]</td>\n",
       "      <td>[@pedroferriz, mi, pedrito, recordar, el]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>@PagesBeatriz #ElINENoSeToca ud y su lacayo de...</td>\n",
       "      <td>[@pagesbeatriz, #elinenosetoca, ud, lacayo, at...</td>\n",
       "      <td>[@pagesbeatriz, ud, su, lacayo, gritar, su, hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>La #DerechaMiserableyCorrupta solo escupe para...</td>\n",
       "      <td>[#derechamiserableycorrupta, solo, escupe, arr...</td>\n",
       "      <td>[el, derechamiserableycorrupta, solo, escupar,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>@_VicenteSerrano @lorenzocordovav De aquí en a...</td>\n",
       "      <td>[@vicenteserrano, @lorenzocordovav, aquí, adel...</td>\n",
       "      <td>[@_vicenteserrano, @lorenzocordovav, demostrar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>@analucia_medina Totalmente de acuerdo contigo...</td>\n",
       "      <td>[@analuciamedina, totalmente, acuerdo, contigo...</td>\n",
       "      <td>[@analucia_medinar, acuerdo, seguir, elinenose...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet  \\\n",
       "0   Lo qué acabó de ver compañeros, un comercial d...   \n",
       "1                         @PedroFerriz #ElIneNoSeToca   \n",
       "2       @ferbelaunzaran @MexicoHablaMx #ElIneNoSeToca   \n",
       "3                     Rositas fresitas #ElIneNoSeToca   \n",
       "4   Hasta el lunes 3 de abril #ElIneNoSeToca y tre...   \n",
       "..                                                ...   \n",
       "95  @PedroFerriz Mi Pedrito, recuerde el #ElINENoS...   \n",
       "96  @PagesBeatriz #ElINENoSeToca ud y su lacayo de...   \n",
       "97  La #DerechaMiserableyCorrupta solo escupe para...   \n",
       "98  @_VicenteSerrano @lorenzocordovav De aquí en a...   \n",
       "99  @analucia_medina Totalmente de acuerdo contigo...   \n",
       "\n",
       "                                          tweet_clean  \\\n",
       "0   [acabó, ver, compañeros, comercial, pri, cuyas...   \n",
       "1                      [@pedroferriz, #elinenosetoca]   \n",
       "2   [@ferbelaunzaran, @mexicohablamx, #elinenosetoca]   \n",
       "3                  [rosita, fresitas, #elinenosetoca]   \n",
       "4   [lunes, 3, abril, #elinenosetoca, tres, mapach...   \n",
       "..                                                ...   \n",
       "95  [@pedroferriz, pedrito, recuerde, #elinenosetoca]   \n",
       "96  [@pagesbeatriz, #elinenosetoca, ud, lacayo, at...   \n",
       "97  [#derechamiserableycorrupta, solo, escupe, arr...   \n",
       "98  [@vicenteserrano, @lorenzocordovav, aquí, adel...   \n",
       "99  [@analuciamedina, totalmente, acuerdo, contigo...   \n",
       "\n",
       "                               tweet_spacy_preprocess  \n",
       "0   [acabar, ver, compañero, uno, comercial, image...  \n",
       "1                                      [@pedroferriz]  \n",
       "2                     [@ferbelaunzar, @mexicohablamx]  \n",
       "3                                   [rosita, fresita]  \n",
       "4   [el, lunes, abril, elinenosetoca, tres, mapach...  \n",
       "..                                                ...  \n",
       "95          [@pedroferriz, mi, pedrito, recordar, el]  \n",
       "96  [@pagesbeatriz, ud, su, lacayo, gritar, su, hi...  \n",
       "97  [el, derechamiserableycorrupta, solo, escupar,...  \n",
       "98  [@_vicenteserrano, @lorenzocordovav, demostrar...  \n",
       "99  [@analucia_medinar, acuerdo, seguir, elinenose...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['tweet','tweet_clean','tweet_spacy_preprocess']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fef9f1e",
   "metadata": {},
   "source": [
    "## 5. Referencias\n",
    "- [Python String Methods](https://docs.python.org/3/library/stdtypes.html) in Python Documentation.\n",
    "- [Text Preprocessing in NLP with Python codes](https://www.analyticsvidhya.com/blog/2021/06/text-preprocessing-in-nlp-with-python-codes/) by Deepanshi, in Analytics Vidhya.\n",
    "- Librería de Python [*Natural Language Toolkit* - `NLTK`](https://www.nltk.org/index.html)\n",
    "- Librería de Python [*Regular expression operations* - `re`](https://docs.python.org/3/library/re.html)\n",
    "- Material público del curso [DSCI 575: Advanced Machine Learning](https://github.com/UBC-MDS/DSCI_575_adv-mach-learn) de UBC MDS.\n",
    "- Python script [preprocess.py](https://github.com/vcuspinera/UBC_MDS_Capstone_BCStats/blob/master/src/data/preprocess.py) del Capstone project de UBC MDS y BC Stats, por Sukriti Trehan, Karanpal Singh, Carlina Kim y Victor Cuspinera."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
