{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18 • Herramientas de texto\n",
    "\n",
    "En este notebook se revisará distintas herramientas para modificar, limpiar, preprocesar texto en Python.\n",
    "\n",
    "## Contenido\n",
    "1. Strings como lista de caracteres\n",
    "2. Preproceso de texto\n",
    "3. Regular expressions (*Regex*)\n",
    "4. spaCy\n",
    "5. Referencias  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Strings como lista de caracteres\n",
    "Anteriormente ya habían trabajado con strings, sin embargo, podemos tratar a un string como una lista de caracteres. Para esto, podemos utilziar los [métodos para *strings* que tiene Python](https://docs.python.org/3/library/stdtypes.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"Mi villano favorito\"\n",
    "\n",
    "# También se puede declarar así:\n",
    "# texto = str(\"Mi villano favorito\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M\n",
      "i\n",
      " \n",
      "v\n",
      "i\n",
      "l\n",
      "l\n",
      "a\n",
      "n\n",
      "o\n",
      " \n",
      "f\n",
      "a\n",
      "v\n",
      "o\n",
      "r\n",
      "i\n",
      "t\n",
      "o\n"
     ]
    }
   ],
   "source": [
    "# Un string es una cadena de caracteres y al imprimirlo con un loop regresa un carácter por renglón\n",
    "for i in texto:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen algunas funciones propias de los *strings* que nos ayudarán para trabajar con textos, como:\n",
    "- **lower**, pone la cadena en minúsculas\n",
    "- **upper**, pone la cadena en mayúsculas\n",
    "- **title**, pone en mayúscula la primera letra de cada palabra de un enunciado\n",
    "- **replace**, para sustituir algún texto\n",
    "- **rfind**, encuentra dentro de una cadena dónde inicia un texto de nuestro interés\n",
    "- **rspilt**, separa un enunciado en palabras (*tokens*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mi villano favorito'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lower\n",
    "texto.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MI VILLANO FAVORITO'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upper\n",
    "texto.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mi Villano Favorito'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# title\n",
    "texto.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mi marciano favorito'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace\n",
    "texto.replace(\"villano\", \"marciano\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rfind\n",
    "texto.rfind(\"villano\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mi', 'villano', 'favorito']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split\n",
    "texto.rsplit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preproceso de texto\n",
    "Usualmente la información en formato de texto se encuentra desordenada y sin estructura. Para poder realizar un mejor análisis es importante \"normalizar\" esta información.\n",
    "\n",
    "Existen distintas herramientas para el preproceso de datos que podemos utilizar para obtener una base de datos limpia, entre las que se encuentran: utilizar letras minúscula, lematización (usar la raíz de la palabra), separa un enunciado en *tokens*, remover puntuación y *stopwords*, entre otras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import snscrape.modules.twitter as sntwitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base de datos inicial (raw)\n",
    "En este caso se consultaron 1,000 tweets con el hashtag #ElINENoSeToca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 34.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Parámetros\n",
    "tweets_list_ine = []\n",
    "maxTweets_ine = 1_000\n",
    "date_initial = \"2022-10-01\"\n",
    "\n",
    "# Get tweets\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('#ElINENoSeToca').get_items()): # se puede añadir esto --> since:'+date_initial\n",
    "        if i>maxTweets_ine-1:\n",
    "            break\n",
    "        tweets_list_ine.append([tweet.user.username, tweet.date, tweet.content])\n",
    "        \n",
    "# Pandas dataframe con tweets que mencionen el hashtag #ElINENoSeToca\n",
    "column_names = (\"username\",\"date\",\"tweet\")\n",
    "df = pd.DataFrame(tweets_list_ine, columns=column_names)\n",
    "#df['day'] = df['date'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sra_hofstadter</td>\n",
       "      <td>2022-11-16 19:53:34+00:00</td>\n",
       "      <td>@EugeniaLeon Hay sra. Si de por sí me daba flo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MatthiVerg</td>\n",
       "      <td>2022-11-16 19:53:30+00:00</td>\n",
       "      <td>@JenniferCuriel9 @ClaudioXGG La MEGAMARCHA 👇😁\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nakauma_takeshi</td>\n",
       "      <td>2022-11-16 19:52:37+00:00</td>\n",
       "      <td>@_VicenteSerrano @lopezobrador_ 😂😂😂 dolió??? #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ToaFeliz3</td>\n",
       "      <td>2022-11-16 19:51:34+00:00</td>\n",
       "      <td>@Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jcquiroz21</td>\n",
       "      <td>2022-11-16 19:51:15+00:00</td>\n",
       "      <td>@EmilioAlvarezI El PRI de los 70’s ha vuelto. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                      date  \\\n",
       "0   sra_hofstadter 2022-11-16 19:53:34+00:00   \n",
       "1       MatthiVerg 2022-11-16 19:53:30+00:00   \n",
       "2  nakauma_takeshi 2022-11-16 19:52:37+00:00   \n",
       "3        ToaFeliz3 2022-11-16 19:51:34+00:00   \n",
       "4       jcquiroz21 2022-11-16 19:51:15+00:00   \n",
       "\n",
       "                                               tweet  \n",
       "0  @EugeniaLeon Hay sra. Si de por sí me daba flo...  \n",
       "1  @JenniferCuriel9 @ClaudioXGG La MEGAMARCHA 👇😁\\...  \n",
       "2  @_VicenteSerrano @lopezobrador_ 😂😂😂 dolió??? #...  \n",
       "3  @Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...  \n",
       "4  @EmilioAlvarezI El PRI de los 70’s ha vuelto. ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# así se ve la base de datos\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-85f15d0b2b2e>:2: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "  df.describe()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>586</td>\n",
       "      <td>980</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>pao_maldo</td>\n",
       "      <td>2022-11-16 19:43:39+00:00</td>\n",
       "      <td>@mexico_rx @MaxKaiser75 @sylbeltrones @CarlosA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-16 13:46:44+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-16 19:53:34+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         username                       date  \\\n",
       "count        1000                       1000   \n",
       "unique        586                        980   \n",
       "top     pao_maldo  2022-11-16 19:43:39+00:00   \n",
       "freq           30                          2   \n",
       "first         NaN  2022-11-16 13:46:44+00:00   \n",
       "last          NaN  2022-11-16 19:53:34+00:00   \n",
       "\n",
       "                                                    tweet  \n",
       "count                                                1000  \n",
       "unique                                                998  \n",
       "top     @mexico_rx @MaxKaiser75 @sylbeltrones @CarlosA...  \n",
       "freq                                                    2  \n",
       "first                                                 NaN  \n",
       "last                                                  NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# descripción general de los datos\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username    586\n",
       "date        980\n",
       "tweet       998\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identificación de valores únicos por variable\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminar signos de puntuación\n",
    "Aquí se eliminan los signos de puntuación con excepción de `#` para poder identificar los hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#library that contains punctuation\n",
    "import string\n",
    "signos_puntuacion = string.punctuation\n",
    "signos_puntuacion = signos_puntuacion.replace(\"#\", \"\")  # quitar '#' de hashtags \n",
    "signos_puntuacion = signos_puntuacion.replace(\"@\", \"\")  # quitar '@' de cuentas\n",
    "signos_puntuacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sra_hofstadter</td>\n",
       "      <td>2022-11-16 19:53:34+00:00</td>\n",
       "      <td>@EugeniaLeon Hay sra. Si de por sí me daba flo...</td>\n",
       "      <td>@EugeniaLeon Hay sra Si de por sí me daba floj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MatthiVerg</td>\n",
       "      <td>2022-11-16 19:53:30+00:00</td>\n",
       "      <td>@JenniferCuriel9 @ClaudioXGG La MEGAMARCHA 👇😁\\...</td>\n",
       "      <td>@JenniferCuriel9 @ClaudioXGG La MEGAMARCHA 👇😁\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nakauma_takeshi</td>\n",
       "      <td>2022-11-16 19:52:37+00:00</td>\n",
       "      <td>@_VicenteSerrano @lopezobrador_ 😂😂😂 dolió??? #...</td>\n",
       "      <td>@VicenteSerrano @lopezobrador 😂😂😂 dolió #ElINE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ToaFeliz3</td>\n",
       "      <td>2022-11-16 19:51:34+00:00</td>\n",
       "      <td>@Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...</td>\n",
       "      <td>@Amadoelquelolea @SCJN Muy de acuerdo  \\nYo si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jcquiroz21</td>\n",
       "      <td>2022-11-16 19:51:15+00:00</td>\n",
       "      <td>@EmilioAlvarezI El PRI de los 70’s ha vuelto. ...</td>\n",
       "      <td>@EmilioAlvarezI El PRI de los 70’s ha vuelto \\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                      date  \\\n",
       "0   sra_hofstadter 2022-11-16 19:53:34+00:00   \n",
       "1       MatthiVerg 2022-11-16 19:53:30+00:00   \n",
       "2  nakauma_takeshi 2022-11-16 19:52:37+00:00   \n",
       "3        ToaFeliz3 2022-11-16 19:51:34+00:00   \n",
       "4       jcquiroz21 2022-11-16 19:51:15+00:00   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  @EugeniaLeon Hay sra. Si de por sí me daba flo...   \n",
       "1  @JenniferCuriel9 @ClaudioXGG La MEGAMARCHA 👇😁\\...   \n",
       "2  @_VicenteSerrano @lopezobrador_ 😂😂😂 dolió??? #...   \n",
       "3  @Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...   \n",
       "4  @EmilioAlvarezI El PRI de los 70’s ha vuelto. ...   \n",
       "\n",
       "                                         tweet_clean  \n",
       "0  @EugeniaLeon Hay sra Si de por sí me daba floj...  \n",
       "1  @JenniferCuriel9 @ClaudioXGG La MEGAMARCHA 👇😁\\...  \n",
       "2  @VicenteSerrano @lopezobrador 😂😂😂 dolió #ElINE...  \n",
       "3  @Amadoelquelolea @SCJN Muy de acuerdo  \\nYo si...  \n",
       "4  @EmilioAlvarezI El PRI de los 70’s ha vuelto \\...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining the function to remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in signos_puntuacion])\n",
    "    return punctuationfree\n",
    "\n",
    "#storing the puntuation free text\n",
    "df['tweet_clean'] = df['tweet'].apply(lambda x:remove_punctuation(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Textos en minúsculas\n",
    "Parte de la normalización es poner todos los textos en minúsculas (o mayúsculas), esto puede servir posteriormente por ejemplo para hacer un conteo de palabras.\n",
    "\n",
    "⚠️ _**Nota**: Al hacer esto existe el riesgo que se pierda información contextual; por ejemplo, dentro de un tweet cuando alguien escribe una palabra específica en mayúsculas y las demás en minúsculas esto conlleva un mayor importancia o aumento en tono de voz._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sra_hofstadter</td>\n",
       "      <td>2022-11-16 19:53:34+00:00</td>\n",
       "      <td>@EugeniaLeon Hay sra. Si de por sí me daba flo...</td>\n",
       "      <td>@eugenialeon hay sra si de por sí me daba floj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MatthiVerg</td>\n",
       "      <td>2022-11-16 19:53:30+00:00</td>\n",
       "      <td>@JenniferCuriel9 @ClaudioXGG La MEGAMARCHA 👇😁\\...</td>\n",
       "      <td>@jennifercuriel9 @claudioxgg la megamarcha 👇😁\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nakauma_takeshi</td>\n",
       "      <td>2022-11-16 19:52:37+00:00</td>\n",
       "      <td>@_VicenteSerrano @lopezobrador_ 😂😂😂 dolió??? #...</td>\n",
       "      <td>@vicenteserrano @lopezobrador 😂😂😂 dolió #eline...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ToaFeliz3</td>\n",
       "      <td>2022-11-16 19:51:34+00:00</td>\n",
       "      <td>@Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...</td>\n",
       "      <td>@amadoelquelolea @scjn muy de acuerdo  \\nyo si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jcquiroz21</td>\n",
       "      <td>2022-11-16 19:51:15+00:00</td>\n",
       "      <td>@EmilioAlvarezI El PRI de los 70’s ha vuelto. ...</td>\n",
       "      <td>@emilioalvarezi el pri de los 70’s ha vuelto \\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                      date  \\\n",
       "0   sra_hofstadter 2022-11-16 19:53:34+00:00   \n",
       "1       MatthiVerg 2022-11-16 19:53:30+00:00   \n",
       "2  nakauma_takeshi 2022-11-16 19:52:37+00:00   \n",
       "3        ToaFeliz3 2022-11-16 19:51:34+00:00   \n",
       "4       jcquiroz21 2022-11-16 19:51:15+00:00   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  @EugeniaLeon Hay sra. Si de por sí me daba flo...   \n",
       "1  @JenniferCuriel9 @ClaudioXGG La MEGAMARCHA 👇😁\\...   \n",
       "2  @_VicenteSerrano @lopezobrador_ 😂😂😂 dolió??? #...   \n",
       "3  @Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...   \n",
       "4  @EmilioAlvarezI El PRI de los 70’s ha vuelto. ...   \n",
       "\n",
       "                                         tweet_clean  \n",
       "0  @eugenialeon hay sra si de por sí me daba floj...  \n",
       "1  @jennifercuriel9 @claudioxgg la megamarcha 👇😁\\...  \n",
       "2  @vicenteserrano @lopezobrador 😂😂😂 dolió #eline...  \n",
       "3  @amadoelquelolea @scjn muy de acuerdo  \\nyo si...  \n",
       "4  @emilioalvarezi el pri de los 70’s ha vuelto \\...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cambiar los tweets a letras minúsculas\n",
    "df['tweet_clean'] = df['tweet_clean'].apply((lambda x: x.lower()))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "Aquí veremos cómo separar los enunciados (*tweets*) en *tokens* (palabras o cadenas de caracteres)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sra_hofstadter</td>\n",
       "      <td>2022-11-16 19:53:34+00:00</td>\n",
       "      <td>@EugeniaLeon Hay sra. Si de por sí me daba flo...</td>\n",
       "      <td>[@eugenialeon, hay, sra, si, de, por, sí, me, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MatthiVerg</td>\n",
       "      <td>2022-11-16 19:53:30+00:00</td>\n",
       "      <td>@JenniferCuriel9 @ClaudioXGG La MEGAMARCHA 👇😁\\...</td>\n",
       "      <td>[@jennifercuriel9, @claudioxgg, la, megamarcha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nakauma_takeshi</td>\n",
       "      <td>2022-11-16 19:52:37+00:00</td>\n",
       "      <td>@_VicenteSerrano @lopezobrador_ 😂😂😂 dolió??? #...</td>\n",
       "      <td>[@vicenteserrano, @lopezobrador, 😂😂😂, dolió, #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ToaFeliz3</td>\n",
       "      <td>2022-11-16 19:51:34+00:00</td>\n",
       "      <td>@Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...</td>\n",
       "      <td>[@amadoelquelolea, @scjn, muy, de, acuerdo, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jcquiroz21</td>\n",
       "      <td>2022-11-16 19:51:15+00:00</td>\n",
       "      <td>@EmilioAlvarezI El PRI de los 70’s ha vuelto. ...</td>\n",
       "      <td>[@emilioalvarezi, el, pri, de, los, 70’s, ha, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                      date  \\\n",
       "0   sra_hofstadter 2022-11-16 19:53:34+00:00   \n",
       "1       MatthiVerg 2022-11-16 19:53:30+00:00   \n",
       "2  nakauma_takeshi 2022-11-16 19:52:37+00:00   \n",
       "3        ToaFeliz3 2022-11-16 19:51:34+00:00   \n",
       "4       jcquiroz21 2022-11-16 19:51:15+00:00   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  @EugeniaLeon Hay sra. Si de por sí me daba flo...   \n",
       "1  @JenniferCuriel9 @ClaudioXGG La MEGAMARCHA 👇😁\\...   \n",
       "2  @_VicenteSerrano @lopezobrador_ 😂😂😂 dolió??? #...   \n",
       "3  @Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...   \n",
       "4  @EmilioAlvarezI El PRI de los 70’s ha vuelto. ...   \n",
       "\n",
       "                                         tweet_clean  \n",
       "0  [@eugenialeon, hay, sra, si, de, por, sí, me, ...  \n",
       "1  [@jennifercuriel9, @claudioxgg, la, megamarcha...  \n",
       "2  [@vicenteserrano, @lopezobrador, 😂😂😂, dolió, #...  \n",
       "3  [@amadoelquelolea, @scjn, muy, de, acuerdo, yo...  \n",
       "4  [@emilioalvarezi, el, pri, de, los, 70’s, ha, ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the tokens per tweet\n",
    "df['tweet_clean'] = df['tweet_clean'].apply(lambda x: x.rsplit())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminar *stopwords*\n",
    "Las *stopwords* son palabras de uso común que no añaden un valor adicional al análisis de texto o que no tienen sentido, por lo que pueden ser eliminadas de nuestra lista de tokens.\n",
    "\n",
    "Existen distintas maneras de obtener la lista de stopwords:  \n",
    "> (1) Crear nuestra propia lista  \n",
    "\n",
    "> (2) Buscar alguna base de datos que contenga la lista de stopwords\n",
    "> - En GitHub encontré una lista de stopwords el el repositorio [Alir3z4/stop-words](https://github.com/Alir3z4/stop-words/blob/master/spanish.txt)\n",
    "> - Una alternativa es una lista de Kaggle [Spanish Stopwords W2V](https://www.kaggle.com/code/mpwolke/spanish-stopwords-w2v)\n",
    "> - Otra alternativa es la lista que da la página [countwordsfree.com](https://countwordsfree.com/stopwords/spanish)\n",
    "\n",
    "> (3) Algo más estandarizado y completo es utilizar la librería de *Natural Language Toolkit* (**NLTK**), la cual tiene listas de stopwords en distintos idiomas, donde (además de inglés) podemos encontrar la lista de palabras en español. Para instalar este paquete así como mayor detalle de uso, revisa la página de la [librería NLTK](https://www.nltk.org/data.html).\n",
    "\n",
    "⚠️ _**Nota**: antes de usar alguna de las opciones anteriores deberás de pensar cuál lista de stopwords se acopla mejor a tus necesidades!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de stopwords en mi lista (1): 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a', 'ante', 'bajo', 'cabe', 'con', 'no', 'de', 'del', 'al', 'tras']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (1) Crear nuestra propia lista de stopwords\n",
    "stopwords_1 = ['a','ante','bajo','cabe','con','no','de','del','al','tras']\n",
    "\n",
    "print(\"Número de stopwords en mi lista (1):\", len(stopwords_1))\n",
    "stopwords_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de stopwords en mi lista (2): 609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'actualmente',\n",
       " 'adelante',\n",
       " 'además',\n",
       " 'afirmó',\n",
       " 'agregó',\n",
       " 'ahora',\n",
       " 'ahí',\n",
       " 'al',\n",
       " 'algo',\n",
       " 'alguna',\n",
       " 'algunas',\n",
       " 'alguno',\n",
       " 'algunos',\n",
       " 'algún']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (2) Buscar alguna base de datos que contenga la lista de stopwords.\n",
    "#     En este ejemplo bajamos la lista de GitHub\n",
    "import urllib3\n",
    "\n",
    "http = urllib3.PoolManager()\n",
    "r = http.request('GET', \"https://raw.githubusercontent.com/Alir3z4/stop-words/master/spanish.txt\")\n",
    "stopwords_2 = r.data.decode('utf-8').replace(\"\\n\",\" \").rsplit()\n",
    "\n",
    "print(\"Número de stopwords en mi lista (2):\", len(stopwords_2))\n",
    "stopwords_2[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de stopwords en de NLTK library (3): 313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['de',\n",
       " 'la',\n",
       " 'que',\n",
       " 'el',\n",
       " 'en',\n",
       " 'y',\n",
       " 'a',\n",
       " 'los',\n",
       " 'del',\n",
       " 'se',\n",
       " 'las',\n",
       " 'por',\n",
       " 'un',\n",
       " 'para',\n",
       " 'con']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (3) Uso de NLP Toolkit library\n",
    "\n",
    "## Para instalar la librería revisa la página: https://www.nltk.org/data.html\n",
    "## Nota, este proceso puede ser tardado...\n",
    "# !pip install nltk\n",
    "# nltk.download()\n",
    "\n",
    "# load library\n",
    "import nltk\n",
    "\n",
    "stopwords_3 = nltk.corpus.stopwords.words('spanish')\n",
    "\n",
    "print(\"Número de stopwords en de NLTK library (3):\", len(stopwords_3))\n",
    "stopwords_3[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vamos a eliminar las stopwords usando la lista que obtivimos de NLTK library (opción 3):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sra_hofstadter</td>\n",
       "      <td>2022-11-16 19:53:34+00:00</td>\n",
       "      <td>@EugeniaLeon Hay sra. Si de por sí me daba flo...</td>\n",
       "      <td>[@eugenialeon, sra, si, daba, flojera, ahora, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MatthiVerg</td>\n",
       "      <td>2022-11-16 19:53:30+00:00</td>\n",
       "      <td>@JenniferCuriel9 @ClaudioXGG La MEGAMARCHA 👇😁\\...</td>\n",
       "      <td>[@jennifercuriel9, @claudioxgg, megamarcha, 👇😁...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nakauma_takeshi</td>\n",
       "      <td>2022-11-16 19:52:37+00:00</td>\n",
       "      <td>@_VicenteSerrano @lopezobrador_ 😂😂😂 dolió??? #...</td>\n",
       "      <td>[@vicenteserrano, @lopezobrador, 😂😂😂, dolió, #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ToaFeliz3</td>\n",
       "      <td>2022-11-16 19:51:34+00:00</td>\n",
       "      <td>@Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...</td>\n",
       "      <td>[@amadoelquelolea, @scjn, acuerdo, si, voy, vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jcquiroz21</td>\n",
       "      <td>2022-11-16 19:51:15+00:00</td>\n",
       "      <td>@EmilioAlvarezI El PRI de los 70’s ha vuelto. ...</td>\n",
       "      <td>[@emilioalvarezi, pri, 70’s, vuelto, @lopezobr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                      date  \\\n",
       "0   sra_hofstadter 2022-11-16 19:53:34+00:00   \n",
       "1       MatthiVerg 2022-11-16 19:53:30+00:00   \n",
       "2  nakauma_takeshi 2022-11-16 19:52:37+00:00   \n",
       "3        ToaFeliz3 2022-11-16 19:51:34+00:00   \n",
       "4       jcquiroz21 2022-11-16 19:51:15+00:00   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  @EugeniaLeon Hay sra. Si de por sí me daba flo...   \n",
       "1  @JenniferCuriel9 @ClaudioXGG La MEGAMARCHA 👇😁\\...   \n",
       "2  @_VicenteSerrano @lopezobrador_ 😂😂😂 dolió??? #...   \n",
       "3  @Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...   \n",
       "4  @EmilioAlvarezI El PRI de los 70’s ha vuelto. ...   \n",
       "\n",
       "                                         tweet_clean  \n",
       "0  [@eugenialeon, sra, si, daba, flojera, ahora, ...  \n",
       "1  [@jennifercuriel9, @claudioxgg, megamarcha, 👇😁...  \n",
       "2  [@vicenteserrano, @lopezobrador, 😂😂😂, dolió, #...  \n",
       "3  [@amadoelquelolea, @scjn, acuerdo, si, voy, vi...  \n",
       "4  [@emilioalvarezi, pri, 70’s, vuelto, @lopezobr...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining the function to remove stopwords from tokenized text\n",
    "def remove_stopwords(text):\n",
    "    output= [i for i in text if i not in stopwords_3]\n",
    "    return output\n",
    "\n",
    "#applying the stopwords function to thet tweets\n",
    "df['tweet_clean'] = df['tweet_clean'].apply(lambda x:remove_stopwords(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lematización\n",
    "Este paso nos servirá para extraer la la raíz de las palabras, para poder \"normalizar\" el texto y realizar un mejor análisis. Aquí nuevamente utilizaremos la librería `NLTK`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sra_hofstadter</td>\n",
       "      <td>2022-11-16 19:53:34+00:00</td>\n",
       "      <td>@EugeniaLeon Hay sra. Si de por sí me daba flo...</td>\n",
       "      <td>[@eugenialeon, sra, si, daba, flojera, ahora, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MatthiVerg</td>\n",
       "      <td>2022-11-16 19:53:30+00:00</td>\n",
       "      <td>@JenniferCuriel9 @ClaudioXGG La MEGAMARCHA 👇😁\\...</td>\n",
       "      <td>[@jennifercuriel9, @claudioxgg, megamarcha, 👇😁...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nakauma_takeshi</td>\n",
       "      <td>2022-11-16 19:52:37+00:00</td>\n",
       "      <td>@_VicenteSerrano @lopezobrador_ 😂😂😂 dolió??? #...</td>\n",
       "      <td>[@vicenteserrano, @lopezobrador, 😂😂😂, dolió, #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ToaFeliz3</td>\n",
       "      <td>2022-11-16 19:51:34+00:00</td>\n",
       "      <td>@Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...</td>\n",
       "      <td>[@amadoelquelolea, @scjn, acuerdo, si, voy, vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jcquiroz21</td>\n",
       "      <td>2022-11-16 19:51:15+00:00</td>\n",
       "      <td>@EmilioAlvarezI El PRI de los 70’s ha vuelto. ...</td>\n",
       "      <td>[@emilioalvarezi, pri, 70’s, vuelto, @lopezobr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                      date  \\\n",
       "0   sra_hofstadter 2022-11-16 19:53:34+00:00   \n",
       "1       MatthiVerg 2022-11-16 19:53:30+00:00   \n",
       "2  nakauma_takeshi 2022-11-16 19:52:37+00:00   \n",
       "3        ToaFeliz3 2022-11-16 19:51:34+00:00   \n",
       "4       jcquiroz21 2022-11-16 19:51:15+00:00   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  @EugeniaLeon Hay sra. Si de por sí me daba flo...   \n",
       "1  @JenniferCuriel9 @ClaudioXGG La MEGAMARCHA 👇😁\\...   \n",
       "2  @_VicenteSerrano @lopezobrador_ 😂😂😂 dolió??? #...   \n",
       "3  @Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...   \n",
       "4  @EmilioAlvarezI El PRI de los 70’s ha vuelto. ...   \n",
       "\n",
       "                                         tweet_clean  \n",
       "0  [@eugenialeon, sra, si, daba, flojera, ahora, ...  \n",
       "1  [@jennifercuriel9, @claudioxgg, megamarcha, 👇😁...  \n",
       "2  [@vicenteserrano, @lopezobrador, 😂😂😂, dolió, #...  \n",
       "3  [@amadoelquelolea, @scjn, acuerdo, si, voy, vi...  \n",
       "4  [@emilioalvarezi, pri, 70’s, vuelto, @lopezobr...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining the object for Lemmatization\n",
    "wordnet_lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "#defining the function for lemmatization\n",
    "def lemmatizer(text):\n",
    "    lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
    "    return lemm_text\n",
    "\n",
    "#lemmatization of our tweets\n",
    "df['tweet_clean'] = df['tweet_clean'].apply(lambda x:lemmatizer(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminar URLs\n",
    "En este caso, también eliminamos las URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sra_hofstadter</td>\n",
       "      <td>2022-11-16 19:53:34+00:00</td>\n",
       "      <td>@EugeniaLeon Hay sra. Si de por sí me daba flo...</td>\n",
       "      <td>[@eugenialeon, sra, si, daba, flojera, ahora, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MatthiVerg</td>\n",
       "      <td>2022-11-16 19:53:30+00:00</td>\n",
       "      <td>@JenniferCuriel9 @ClaudioXGG La MEGAMARCHA 👇😁\\...</td>\n",
       "      <td>[@jennifercuriel9, @claudioxgg, megamarcha, 👇😁...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nakauma_takeshi</td>\n",
       "      <td>2022-11-16 19:52:37+00:00</td>\n",
       "      <td>@_VicenteSerrano @lopezobrador_ 😂😂😂 dolió??? #...</td>\n",
       "      <td>[@vicenteserrano, @lopezobrador, 😂😂😂, dolió, #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ToaFeliz3</td>\n",
       "      <td>2022-11-16 19:51:34+00:00</td>\n",
       "      <td>@Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...</td>\n",
       "      <td>[@amadoelquelolea, @scjn, acuerdo, si, voy, vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jcquiroz21</td>\n",
       "      <td>2022-11-16 19:51:15+00:00</td>\n",
       "      <td>@EmilioAlvarezI El PRI de los 70’s ha vuelto. ...</td>\n",
       "      <td>[@emilioalvarezi, pri, 70’s, vuelto, @lopezobr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                      date  \\\n",
       "0   sra_hofstadter 2022-11-16 19:53:34+00:00   \n",
       "1       MatthiVerg 2022-11-16 19:53:30+00:00   \n",
       "2  nakauma_takeshi 2022-11-16 19:52:37+00:00   \n",
       "3        ToaFeliz3 2022-11-16 19:51:34+00:00   \n",
       "4       jcquiroz21 2022-11-16 19:51:15+00:00   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  @EugeniaLeon Hay sra. Si de por sí me daba flo...   \n",
       "1  @JenniferCuriel9 @ClaudioXGG La MEGAMARCHA 👇😁\\...   \n",
       "2  @_VicenteSerrano @lopezobrador_ 😂😂😂 dolió??? #...   \n",
       "3  @Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...   \n",
       "4  @EmilioAlvarezI El PRI de los 70’s ha vuelto. ...   \n",
       "\n",
       "                                         tweet_clean  \n",
       "0  [@eugenialeon, sra, si, daba, flojera, ahora, ...  \n",
       "1  [@jennifercuriel9, @claudioxgg, megamarcha, 👇😁...  \n",
       "2  [@vicenteserrano, @lopezobrador, 😂😂😂, dolió, #...  \n",
       "3  [@amadoelquelolea, @scjn, acuerdo, si, voy, vi...  \n",
       "4  [@emilioalvarezi, pri, 70’s, vuelto, @lopezobr...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def erase_urls(text):\n",
    "    output = [i for i in text if i.rfind(\"http\")==-1]\n",
    "    return output\n",
    "\n",
    "# texto.rfind(\"villano\")\n",
    "df['tweet_clean'] = df['tweet_clean'].apply(lambda x:erase_urls(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado final de preproceso (BD final)\n",
    "A continuación se muestran los textos iniciales en la columna \"tweets\", y la información preprocesada en la columna \"tweet_clean\", a manera de comparación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@EugeniaLeon Hay sra. Si de por sí me daba flo...</td>\n",
       "      <td>[@eugenialeon, sra, si, daba, flojera, ahora, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@JenniferCuriel9 @ClaudioXGG La MEGAMARCHA 👇😁\\...</td>\n",
       "      <td>[@jennifercuriel9, @claudioxgg, megamarcha, 👇😁...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@_VicenteSerrano @lopezobrador_ 😂😂😂 dolió??? #...</td>\n",
       "      <td>[@vicenteserrano, @lopezobrador, 😂😂😂, dolió, #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...</td>\n",
       "      <td>[@amadoelquelolea, @scjn, acuerdo, si, voy, vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@EmilioAlvarezI El PRI de los 70’s ha vuelto. ...</td>\n",
       "      <td>[@emilioalvarezi, pri, 70’s, vuelto, @lopezobr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Verdad que si lo quieren desaparecer?\\nSólo lo...</td>\n",
       "      <td>[verdad, si, quieren, desaparecer, sólo, abyec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>@lopezobrador_ Y AMLO en vez de gobernar, sale...</td>\n",
       "      <td>[@lopezobrador, amlo, vez, gobernar, sale, des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Lo único que saben es robar, mentir y destruir...</td>\n",
       "      <td>[único, saben, robar, mentir, destruir, #moren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>@EugeniaLeon @lopezobrador_ #ElINENoSeToca \\n#...</td>\n",
       "      <td>[@eugenialeon, @lopezobrador, #elinenosetoca, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>@santiagobaeza @lopezobrador_ la gente se hart...</td>\n",
       "      <td>[@santiagobaeza, @lopezobrador, gente, hartó, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet  \\\n",
       "0    @EugeniaLeon Hay sra. Si de por sí me daba flo...   \n",
       "1    @JenniferCuriel9 @ClaudioXGG La MEGAMARCHA 👇😁\\...   \n",
       "2    @_VicenteSerrano @lopezobrador_ 😂😂😂 dolió??? #...   \n",
       "3    @Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...   \n",
       "4    @EmilioAlvarezI El PRI de los 70’s ha vuelto. ...   \n",
       "..                                                 ...   \n",
       "995  Verdad que si lo quieren desaparecer?\\nSólo lo...   \n",
       "996  @lopezobrador_ Y AMLO en vez de gobernar, sale...   \n",
       "997  Lo único que saben es robar, mentir y destruir...   \n",
       "998  @EugeniaLeon @lopezobrador_ #ElINENoSeToca \\n#...   \n",
       "999  @santiagobaeza @lopezobrador_ la gente se hart...   \n",
       "\n",
       "                                           tweet_clean  \n",
       "0    [@eugenialeon, sra, si, daba, flojera, ahora, ...  \n",
       "1    [@jennifercuriel9, @claudioxgg, megamarcha, 👇😁...  \n",
       "2    [@vicenteserrano, @lopezobrador, 😂😂😂, dolió, #...  \n",
       "3    [@amadoelquelolea, @scjn, acuerdo, si, voy, vi...  \n",
       "4    [@emilioalvarezi, pri, 70’s, vuelto, @lopezobr...  \n",
       "..                                                 ...  \n",
       "995  [verdad, si, quieren, desaparecer, sólo, abyec...  \n",
       "996  [@lopezobrador, amlo, vez, gobernar, sale, des...  \n",
       "997  [único, saben, robar, mentir, destruir, #moren...  \n",
       "998  [@eugenialeon, @lopezobrador, #elinenosetoca, ...  \n",
       "999  [@santiagobaeza, @lopezobrador, gente, hartó, ...  \n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['tweet', 'tweet_clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo de tweet...\n",
      "- original tweet:\n",
      " @JenniferCuriel9 @ClaudioXGG La MEGAMARCHA 👇😁\n",
      "#ElINENoSeToca https://t.co/rJnuVP12US \n",
      "\n",
      "- tweet clean:\n",
      " ['@jennifercuriel9', '@claudioxgg', 'megamarcha', '👇😁', '#elinenosetoca']\n"
     ]
    }
   ],
   "source": [
    "print(\"Ejemplo de tweet...\\n- original tweet:\\n\",df['tweet'][1],\n",
    "      \"\\n\\n- tweet clean:\\n\", df['tweet_clean'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Regular expressions (*Regex*)\n",
    "Las expresiones regulares mejor conocidas como *regex* son una herramienta que nos sirve para trabajar con texto, con el cual se pueden realziar distintas operaciones como búsqueda o reemplazo de un texto específico.\n",
    "\n",
    "Existen distintos operadores que se utilizan en *regex*, estos son los que utilizaremos para nuestros ejemplos. \n",
    "\n",
    "\n",
    "|Operador|Descripción (_en inglés_)|\n",
    "|:------:|:----------------------|\n",
    "|. (punto)|In the default mode, this matches any character except a newline. If the DOTALL flag has been specified, this matches any character including a newline.|\n",
    "|* (asterisco) |Causes the resulting RE to match 0 or more repetitions of the preceding RE, as many repetitions as are possible. ab* will match ‘a’, ‘ab’, or ‘a’ followed by any number of ‘b’s.|\n",
    "|+ (más) |Causes the resulting RE to match 1 or more repetitions of the preceding RE. ab+ will match ‘a’ followed by any non-zero number of ‘b’s; it will not match just ‘a’.|\n",
    "|[ ]| Used to indicate a set of characters. In a set:<ul><li>Characters can be listed individually, e.g. [amk] will match 'a', 'm', or 'k'.</li><li>Ranges of characters can be indicated by giving two characters and separating them by a '-', for example [a-z] will match any lowercase ASCII letter, [0-5][0-9] will match all the two-digits numbers from 00 to 59, and [0-9A-Fa-f] will match any hexadecimal digit. If - is escaped (e.g. [a\\-z]) or if it’s placed as the first or last character (e.g. [-a] or [a-]), it will match a literal '-'.</li><li>Special characters lose their special meaning inside sets. For example, [(+*)] will match any of the literal characters '(', '+', '*', or ')'.</li></ul>|\n",
    "|\\n |line break|\n",
    "\n",
    "⚠️ Se recomienda ampliamente que revisen la página de la [librería **`re`** - *Regular expression operations*](https://docs.python.org/3/library/re.html) para identificar todos los operadores, documentación y ejemplos de como utilizar _regex_.\n",
    "\n",
    "📌 Si les interesa practicar el uso de _regex_, les recomiendo la página de [regexr.com](https://regexr.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load regex library\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracto de canción \"El amor\" de Arjona, link: https://www.letras.com/arjona-ricardo/1963651/\n",
    "texto = \"\"\"El amor tiene firma de autor\n",
    "En las causas pérdidas\n",
    "El amor siempre empieza soñando\n",
    "Y termina en insomnio\n",
    "Es un acto profundo de fe\n",
    "Que huele a mentira\n",
    "El amor baila al son que le toquen\n",
    "Sea Dios o el demonio\n",
    "Sea Dios o el demonio\n",
    "\n",
    "El amor es la guerra pérdida\n",
    "Entre el sexo y la risa\n",
    "Es la llave con que abres\n",
    "El grifo del agua en los ojos\n",
    "Es el tiempo más lento del mundo\n",
    "Cuando va de prisa\n",
    "El amor se abre paso despacio\n",
    "No importa el cerrojo\n",
    "\n",
    "El amor es la arrogancia\n",
    "De aferrarse a lo imposible\n",
    "Es buscar en otra parte\n",
    "Lo que no encuentras en ti\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encontrar un texto usando _regex_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['El amor tiene firma de autor',\n",
       " 'El amor siempre empieza soñando',\n",
       " 'El amor baila al son que le toquen',\n",
       " 'El amor es la guerra pérdida',\n",
       " 'El amor se abre paso despacio',\n",
       " 'El amor es la arrogancia']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encontrar todos los enunciados que tengan la palabra 'amor'\n",
    "re.findall(r'.*[A|a]mor.*', texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sustituir una palabra, frase o cadena de caracterés por otro texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El CePiLLo dE DiEnTeS tiene firma de autor. En las causas pérdidas. El CePiLLo dE DiEnTeS siempre empieza soñando. Y termina en insomnio. Es un acto profundo de fe. Que huele a mentira. El CePiLLo dE DiEnTeS baila al son que le toquen. Sea Dios o el demonio. Sea Dios o el demonio. El CePiLLo dE DiEnTeS es la guerra pérdida. Entre el sexo y la risa. Es la llave con que abres. El grifo del agua en los ojos. Es el tiempo más lento del mundo. Cuando va de prisa. El CePiLLo dE DiEnTeS se abre paso despacio. No importa el cerrojo. El CePiLLo dE DiEnTeS es la arrogancia. De aferrarse a lo imposible. Es buscar en otra parte. Lo que no encuentras en ti. '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Substituir la palabra 'amor' por 'cepillo de dientes'\n",
    "texto_sub = re.sub('[A|a]mor', 'CePiLLo dE DiEnTeS', texto)  # cambia la palabra\n",
    "texto_sub = re.sub('\\n+', '. ', texto_sub)  # cambia el salto de dos renglones por un punto \n",
    "texto_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividir el texto en una lista de strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['El amor tiene firma de autor',\n",
       " 'En las causas pérdidas',\n",
       " 'El amor siempre empieza soñando',\n",
       " 'Y termina en insomnio',\n",
       " 'Es un acto profundo de fe',\n",
       " 'Que huele a mentira',\n",
       " 'El amor baila al son que le toquen',\n",
       " 'Sea Dios o el demonio',\n",
       " 'Sea Dios o el demonio',\n",
       " 'El amor es la guerra pérdida',\n",
       " 'Entre el sexo y la risa',\n",
       " 'Es la llave con que abres',\n",
       " 'El grifo del agua en los ojos',\n",
       " 'Es el tiempo más lento del mundo',\n",
       " 'Cuando va de prisa',\n",
       " 'El amor se abre paso despacio',\n",
       " 'No importa el cerrojo',\n",
       " 'El amor es la arrogancia',\n",
       " 'De aferrarse a lo imposible',\n",
       " 'Es buscar en otra parte',\n",
       " 'Lo que no encuentras en ti',\n",
       " '']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(\"\\n+\", texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install spaCy webpage: https://spacy.io/usage\n",
    "# ! conda install -c conda-forge spacy  # <-install spaCy\n",
    "# ! python -m spacy download en_core_web_sm   # <-spaCy English pipeline optimized for CPU.\n",
    "# ! python -m spacy download es_core_news_sm  # <-spaCy Spanish pipeline optimized for CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load library\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtener características de cada *token*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enunciado:\n",
      " Me llegó un email al correo leo234@gmail.com que dice: \"OMG! El señor Carlos rompió el control del televisor hoy y tuve que comprar otro en www.amazon.com.mx\". \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>dep</th>\n",
       "      <th>is_email</th>\n",
       "      <th>is_url</th>\n",
       "      <th>next_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Me</td>\n",
       "      <td>yo</td>\n",
       "      <td>PRON</td>\n",
       "      <td>iobj</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>llegó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llegó</td>\n",
       "      <td>llegar</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>llegó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>un</td>\n",
       "      <td>uno</td>\n",
       "      <td>DET</td>\n",
       "      <td>det</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>email</td>\n",
       "      <td>email</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>llegó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>al</td>\n",
       "      <td>al</td>\n",
       "      <td>ADP</td>\n",
       "      <td>case</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>correo</td>\n",
       "      <td>correo</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>obl</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>llegó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>leo234@gmail.com</td>\n",
       "      <td>leo234@gmail.com</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>appos</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>correo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>que</td>\n",
       "      <td>que</td>\n",
       "      <td>PRON</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>dice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dice</td>\n",
       "      <td>decir</td>\n",
       "      <td>VERB</td>\n",
       "      <td>csubj</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>llegó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>OMG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"</td>\n",
       "      <td>\"</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>OMG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OMG</td>\n",
       "      <td>OMG</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>obj</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>dice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>OMG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>El</td>\n",
       "      <td>el</td>\n",
       "      <td>DET</td>\n",
       "      <td>det</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>señor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>señor</td>\n",
       "      <td>señor</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>rompió</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Carlos</td>\n",
       "      <td>Carlos</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>appos</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>señor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rompió</td>\n",
       "      <td>romper</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>rompió</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>el</td>\n",
       "      <td>el</td>\n",
       "      <td>DET</td>\n",
       "      <td>det</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>control</td>\n",
       "      <td>control</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>obj</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>rompió</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>del</td>\n",
       "      <td>del</td>\n",
       "      <td>ADP</td>\n",
       "      <td>case</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>televisor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>televisor</td>\n",
       "      <td>televisor</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>hoy</td>\n",
       "      <td>hoy</td>\n",
       "      <td>ADV</td>\n",
       "      <td>advmod</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>rompió</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>cc</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>tuve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tuve</td>\n",
       "      <td>tener</td>\n",
       "      <td>VERB</td>\n",
       "      <td>conj</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>rompió</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>que</td>\n",
       "      <td>que</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>cc</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>comprar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>comprar</td>\n",
       "      <td>comprar</td>\n",
       "      <td>VERB</td>\n",
       "      <td>conj</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>tuve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>otro</td>\n",
       "      <td>otro</td>\n",
       "      <td>PRON</td>\n",
       "      <td>obj</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>comprar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>ADP</td>\n",
       "      <td>case</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>www.amazon.com.mx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>www.amazon.com.mx</td>\n",
       "      <td>www.amazon.com.mx</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>obl</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>comprar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\"</td>\n",
       "      <td>\"</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>rompió</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>rompió</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 text              lemma    pos     dep  is_email  is_url  \\\n",
       "0                  Me                 yo   PRON    iobj     False   False   \n",
       "1               llegó             llegar   VERB    ROOT     False   False   \n",
       "2                  un                uno    DET     det     False   False   \n",
       "3               email              email   NOUN   nsubj     False   False   \n",
       "4                  al                 al    ADP    case     False   False   \n",
       "5              correo             correo   NOUN     obl     False   False   \n",
       "6    leo234@gmail.com   leo234@gmail.com  PROPN   appos      True   False   \n",
       "7                 que                que   PRON   nsubj     False   False   \n",
       "8                dice              decir   VERB   csubj     False   False   \n",
       "9                   :                  :  PUNCT   punct     False   False   \n",
       "10                  \"                  \"  PUNCT   punct     False   False   \n",
       "11                OMG                OMG  PROPN     obj     False   False   \n",
       "12                  !                  !  PUNCT   punct     False   False   \n",
       "13                 El                 el    DET     det     False   False   \n",
       "14              señor              señor   NOUN   nsubj     False   False   \n",
       "15             Carlos             Carlos  PROPN   appos     False   False   \n",
       "16             rompió             romper   VERB    ROOT     False   False   \n",
       "17                 el                 el    DET     det     False   False   \n",
       "18            control            control   NOUN     obj     False   False   \n",
       "19                del                del    ADP    case     False   False   \n",
       "20          televisor          televisor   NOUN    nmod     False   False   \n",
       "21                hoy                hoy    ADV  advmod     False   False   \n",
       "22                  y                  y  CCONJ      cc     False   False   \n",
       "23               tuve              tener   VERB    conj     False   False   \n",
       "24                que                que  SCONJ      cc     False   False   \n",
       "25            comprar            comprar   VERB    conj     False   False   \n",
       "26               otro               otro   PRON     obj     False   False   \n",
       "27                 en                 en    ADP    case     False   False   \n",
       "28  www.amazon.com.mx  www.amazon.com.mx  PROPN     obl     False    True   \n",
       "29                  \"                  \"  PUNCT   punct     False   False   \n",
       "30                  .                  .  PUNCT   punct     False   False   \n",
       "\n",
       "            next_text  \n",
       "0               llegó  \n",
       "1               llegó  \n",
       "2               email  \n",
       "3               llegó  \n",
       "4              correo  \n",
       "5               llegó  \n",
       "6              correo  \n",
       "7                dice  \n",
       "8               llegó  \n",
       "9                 OMG  \n",
       "10                OMG  \n",
       "11               dice  \n",
       "12                OMG  \n",
       "13              señor  \n",
       "14             rompió  \n",
       "15              señor  \n",
       "16             rompió  \n",
       "17            control  \n",
       "18             rompió  \n",
       "19          televisor  \n",
       "20            control  \n",
       "21             rompió  \n",
       "22               tuve  \n",
       "23             rompió  \n",
       "24            comprar  \n",
       "25               tuve  \n",
       "26            comprar  \n",
       "27  www.amazon.com.mx  \n",
       "28            comprar  \n",
       "29             rompió  \n",
       "30             rompió  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load spaCy Spanish pipeline optimized\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "# ejemplo\n",
    "enunciado = 'Me llegó un email al correo leo234@gmail.com que dice: \"OMG! El señor Carlos rompió el control del televisor hoy y tuve que \\\n",
    "comprar otro en www.amazon.com.mx\".'\n",
    "\n",
    "# volver el enunciado un objeto tipo NLP\n",
    "doc = nlp(enunciado) #(sentences[0])\n",
    "print(\"Enunciado:\\n\",doc.text,\"\\n\")\n",
    "\n",
    "# Para cada token (palabra/cadena) se obtienen distintas características:\n",
    "# - texto\n",
    "# - tag con tipo de texto: noun, verb, determinant, adverb, conjunction\n",
    "# - dep: dependenxy\n",
    "# - like_email: identifica si el token es un email\n",
    "# - like_url: identifica si el token es una página web\n",
    "list_tokens = []\n",
    "for token in doc:\n",
    "    # print(token.text, token.pos_, token.dep_, token.like_email)\n",
    "    list_tokens.append([token.text,token.lemma_,token.pos_,token.dep_,token.like_email,\n",
    "                        token.like_url, token.head.text])\n",
    "\n",
    "# Revisar algunas de las características de cada token\n",
    "pd.DataFrame(list_tokens, columns=['text','lemma','pos','dep','is_email','is_url','next_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preproceso con spaCy\n",
    "Ejemplo de función para preproceso usando spaCy, Regex y métodos de strings, comparando resultados con el del preproceso que se vio al inicio de este Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text,\n",
    "               min_token_len = 2,\n",
    "               irrelevant_pos = ['PRON', 'SPACE', 'PUNCT', 'ADV', 'ADP', 'CCONJ', 'AUX', 'PRP'],\n",
    "               avoid_entities = ['PERSON', 'ORG', 'LOC', 'GPE']):\n",
    "    # note: Didn't use the following options in the `preprocess_comments`\n",
    "    #    - 'PROPN', erase proper names, but also words as orange.\n",
    "    #    - 'DET', removes the word 'no', which changes the meaning.\n",
    "    \"\"\"\n",
    "    Function that identify sensible information, anonymize and transforms\n",
    "    the data in a useful format for using with tokens.\n",
    "    Parameters\n",
    "    -------------\n",
    "    text : (list)\n",
    "        the list of text to be preprocessed\n",
    "    irrelevant_pos : (list)\n",
    "        a list of irrelevant 'pos' tags\n",
    "    avoid_entities : (list)\n",
    "        a list of entity labels to be avoided\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    (list) list of preprocessed text\n",
    "\n",
    "    Example\n",
    "    -------------\n",
    "    example = [\"Hello, I'm George and I love swimming!\",\n",
    "                \"I am a really good cook; what about you?\",\n",
    "                \"Contact me at george23@gmail.com\"]\n",
    "    preprocess(example)\n",
    "    (output:) ['hello love swimming', 'good cook', 'contact']\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    others = [\"'s\", \"the\", \"that\", \"this\", \"to\", \"-PRON-\"]\n",
    "    # comment: \"-PRON-\" is a lemma for \"my\", \"your\", etc.\n",
    "\n",
    "    # function\n",
    "    for sent in text:\n",
    "        # <string methods>\n",
    "        sent = str(sent).lower()\n",
    "        \n",
    "        # <regex>\n",
    "        sent = re.sub(r\"(F|f)acebook\", \"social media\", sent)\n",
    "        sent = re.sub(r\"(T|t)witter\", \"social media\", sent)\n",
    "        sent = re.sub(r\"(I|i)nstagram\", \"social media\", sent)\n",
    "        \n",
    "        result_sent = []\n",
    "        \n",
    "        # <spaCy>\n",
    "        doc = nlp(sent)\n",
    "        entities = [str(ent) for ent in doc.ents if ent.label_ in avoid_entities]\n",
    "                   # This helps to detect names of persons, organization and dates\n",
    "        for token in doc:            \n",
    "            if (token.like_email or\n",
    "                token.like_url or\n",
    "                token.pos_ in irrelevant_pos or\n",
    "                str(token) in entities or\n",
    "                str(token.lemma_) in others or\n",
    "                len(token) < min_token_len):\n",
    "                continue\n",
    "            else:\n",
    "                result_sent.append(token.lemma_)\n",
    "        result.append(result_sent)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess tweets\n",
    "df['tweet_spacy_preprocess'] = preprocess(df['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_clean</th>\n",
       "      <th>tweet_spacy_preprocess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@EugeniaLeon Hay sra. Si de por sí me daba flo...</td>\n",
       "      <td>[@eugenialeon, sra, si, daba, flojera, ahora, ...</td>\n",
       "      <td>[@eugenialeon, si, dar, flojera, bueno, porque...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@JenniferCuriel9 @ClaudioXGG La MEGAMARCHA 👇😁\\...</td>\n",
       "      <td>[@jennifercuriel9, @claudioxgg, megamarcha, 👇😁...</td>\n",
       "      <td>[@jennifercuriel9, @claudioxgg, el, megamarcha]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@_VicenteSerrano @lopezobrador_ 😂😂😂 dolió??? #...</td>\n",
       "      <td>[@vicenteserrano, @lopezobrador, 😂😂😂, dolió, #...</td>\n",
       "      <td>[@_vicenteserrano, @lopezobrador, doler, eline...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...</td>\n",
       "      <td>[@amadoelquelolea, @scjn, acuerdo, si, voy, vi...</td>\n",
       "      <td>[@scjn, acuerdo, si, ir, el, visita, cuanta, v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@EmilioAlvarezI El PRI de los 70’s ha vuelto. ...</td>\n",
       "      <td>[@emilioalvarezi, pri, 70’s, vuelto, @lopezobr...</td>\n",
       "      <td>[@emilioalvarezi, el, el, 70’, volver, @lopezo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Verdad que si lo quieren desaparecer?\\nSólo lo...</td>\n",
       "      <td>[verdad, si, quieren, desaparecer, sólo, abyec...</td>\n",
       "      <td>[verdad, que, si, querer, desaparecer, el, aby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>@lopezobrador_ Y AMLO en vez de gobernar, sale...</td>\n",
       "      <td>[@lopezobrador, amlo, vez, gobernar, sale, des...</td>\n",
       "      <td>[@lopezobrador, amlo, vez, gobernar, salir, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Lo único que saben es robar, mentir y destruir...</td>\n",
       "      <td>[único, saben, robar, mentir, destruir, #moren...</td>\n",
       "      <td>[único, saber, robar, mentir, destruir, morena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>@EugeniaLeon @lopezobrador_ #ElINENoSeToca \\n#...</td>\n",
       "      <td>[@eugenialeon, @lopezobrador, #elinenosetoca, ...</td>\n",
       "      <td>[@eugenialeon, @lopezobrador, elinenosetoco, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>@santiagobaeza @lopezobrador_ la gente se hart...</td>\n",
       "      <td>[@santiagobaeza, @lopezobrador, gente, hartó, ...</td>\n",
       "      <td>[@santiagobaeza, el, gente, hartar, su, gobier...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet  \\\n",
       "0    @EugeniaLeon Hay sra. Si de por sí me daba flo...   \n",
       "1    @JenniferCuriel9 @ClaudioXGG La MEGAMARCHA 👇😁\\...   \n",
       "2    @_VicenteSerrano @lopezobrador_ 😂😂😂 dolió??? #...   \n",
       "3    @Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...   \n",
       "4    @EmilioAlvarezI El PRI de los 70’s ha vuelto. ...   \n",
       "..                                                 ...   \n",
       "995  Verdad que si lo quieren desaparecer?\\nSólo lo...   \n",
       "996  @lopezobrador_ Y AMLO en vez de gobernar, sale...   \n",
       "997  Lo único que saben es robar, mentir y destruir...   \n",
       "998  @EugeniaLeon @lopezobrador_ #ElINENoSeToca \\n#...   \n",
       "999  @santiagobaeza @lopezobrador_ la gente se hart...   \n",
       "\n",
       "                                           tweet_clean  \\\n",
       "0    [@eugenialeon, sra, si, daba, flojera, ahora, ...   \n",
       "1    [@jennifercuriel9, @claudioxgg, megamarcha, 👇😁...   \n",
       "2    [@vicenteserrano, @lopezobrador, 😂😂😂, dolió, #...   \n",
       "3    [@amadoelquelolea, @scjn, acuerdo, si, voy, vi...   \n",
       "4    [@emilioalvarezi, pri, 70’s, vuelto, @lopezobr...   \n",
       "..                                                 ...   \n",
       "995  [verdad, si, quieren, desaparecer, sólo, abyec...   \n",
       "996  [@lopezobrador, amlo, vez, gobernar, sale, des...   \n",
       "997  [único, saben, robar, mentir, destruir, #moren...   \n",
       "998  [@eugenialeon, @lopezobrador, #elinenosetoca, ...   \n",
       "999  [@santiagobaeza, @lopezobrador, gente, hartó, ...   \n",
       "\n",
       "                                tweet_spacy_preprocess  \n",
       "0    [@eugenialeon, si, dar, flojera, bueno, porque...  \n",
       "1      [@jennifercuriel9, @claudioxgg, el, megamarcha]  \n",
       "2    [@_vicenteserrano, @lopezobrador, doler, eline...  \n",
       "3    [@scjn, acuerdo, si, ir, el, visita, cuanta, v...  \n",
       "4    [@emilioalvarezi, el, el, 70’, volver, @lopezo...  \n",
       "..                                                 ...  \n",
       "995  [verdad, que, si, querer, desaparecer, el, aby...  \n",
       "996  [@lopezobrador, amlo, vez, gobernar, salir, de...  \n",
       "997  [único, saber, robar, mentir, destruir, morena...  \n",
       "998  [@eugenialeon, @lopezobrador, elinenosetoco, y...  \n",
       "999  [@santiagobaeza, el, gente, hartar, su, gobier...  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['tweet','tweet_clean','tweet_spacy_preprocess']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Referencias\n",
    "- [Python String Methods](https://docs.python.org/3/library/stdtypes.html) in Python Documentation.\n",
    "- [Text Preprocessing in NLP with Python codes](https://www.analyticsvidhya.com/blog/2021/06/text-preprocessing-in-nlp-with-python-codes/) by Deepanshi, in Analytics Vidhya.\n",
    "- Librería de Python [*Natural Language Toolkit* - `NLTK`](https://www.nltk.org/index.html)\n",
    "- Librería de Python [*Regular expression operations* - `re`](https://docs.python.org/3/library/re.html)\n",
    "- Material público del curso [DSCI 575: Advanced Machine Learning](https://github.com/UBC-MDS/DSCI_575_adv-mach-learn) de UBC MDS.\n",
    "- Python script [preprocess.py](https://github.com/vcuspinera/UBC_MDS_Capstone_BCStats/blob/master/src/data/preprocess.py) del Capstone project de UBC MDS y BC Stats, por Sukriti Trehan, Karanpal Singh, Carlina Kim y Victor Cuspinera."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
