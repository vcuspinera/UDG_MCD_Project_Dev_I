{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18 â€¢ Herramientas de texto\n",
    "\n",
    "En este notebook se revisarÃ¡ distintas herramientas para modificar, limpiar, preprocesar texto en Python.\n",
    "\n",
    "## Contenido\n",
    "1. Strings como lista de caracteres\n",
    "2. Preproceso de texto\n",
    "3. Regular expressions (*Regex*)\n",
    "4. spaCy\n",
    "5. Referencias  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Strings como lista de caracteres\n",
    "Anteriormente ya habÃ­an trabajado con strings, sin embargo, podemos tratar a un string como una lista de caracteres. Para esto, podemos utilziar los [mÃ©todos para *strings* que tiene Python](https://docs.python.org/3/library/stdtypes.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"Mi villano favorito\"\n",
    "\n",
    "# TambiÃ©n se puede declarar asÃ­:\n",
    "# texto = str(\"Mi villano favorito\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M\n",
      "i\n",
      " \n",
      "v\n",
      "i\n",
      "l\n",
      "l\n",
      "a\n",
      "n\n",
      "o\n",
      " \n",
      "f\n",
      "a\n",
      "v\n",
      "o\n",
      "r\n",
      "i\n",
      "t\n",
      "o\n"
     ]
    }
   ],
   "source": [
    "# Un string es una cadena de caracteres y al imprimirlo con un loop regresa un carÃ¡cter por renglÃ³n\n",
    "for i in texto:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen algunas funciones propias de los *strings* que nos ayudarÃ¡n para trabajar con textos, como:\n",
    "- **lower**, pone la cadena en minÃºsculas\n",
    "- **upper**, pone la cadena en mayÃºsculas\n",
    "- **title**, pone en mayÃºscula la primera letra de cada palabra de un enunciado\n",
    "- **replace**, para sustituir algÃºn texto\n",
    "- **rfind**, encuentra dentro de una cadena dÃ³nde inicia un texto de nuestro interÃ©s\n",
    "- **rspilt**, separa un enunciado en palabras (*tokens*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mi villano favorito'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lower\n",
    "texto.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MI VILLANO FAVORITO'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upper\n",
    "texto.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mi Villano Favorito'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# title\n",
    "texto.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mi marciano favorito'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace\n",
    "texto.replace(\"villano\", \"marciano\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rfind\n",
    "texto.rfind(\"villano\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mi', 'villano', 'favorito']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split\n",
    "texto.rsplit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preproceso de texto\n",
    "Usualmente la informaciÃ³n en formato de texto se encuentra desordenada y sin estructura. Para poder realizar un mejor anÃ¡lisis es importante \"normalizar\" esta informaciÃ³n.\n",
    "\n",
    "Existen distintas herramientas para el preproceso de datos que podemos utilizar para obtener una base de datos limpia, entre las que se encuentran: utilizar letras minÃºscula, lematizaciÃ³n (usar la raÃ­z de la palabra), separa un enunciado en *tokens*, remover puntuaciÃ³n y *stopwords*, entre otras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import snscrape.modules.twitter as sntwitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base de datos inicial (raw)\n",
    "En este caso se consultaron 1,000 tweets con el hashtag #ElINENoSeToca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 34.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# ParÃ¡metros\n",
    "tweets_list_ine = []\n",
    "maxTweets_ine = 1_000\n",
    "date_initial = \"2022-10-01\"\n",
    "\n",
    "# Get tweets\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('#ElINENoSeToca').get_items()): # se puede aÃ±adir esto --> since:'+date_initial\n",
    "        if i>maxTweets_ine-1:\n",
    "            break\n",
    "        tweets_list_ine.append([tweet.user.username, tweet.date, tweet.content])\n",
    "        \n",
    "# Pandas dataframe con tweets que mencionen el hashtag #ElINENoSeToca\n",
    "column_names = (\"username\",\"date\",\"tweet\")\n",
    "df = pd.DataFrame(tweets_list_ine, columns=column_names)\n",
    "#df['day'] = df['date'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sra_hofstadter</td>\n",
       "      <td>2022-11-16 19:53:34+00:00</td>\n",
       "      <td>@EugeniaLeon Hay sra. Si de por sÃ­ me daba flo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MatthiVerg</td>\n",
       "      <td>2022-11-16 19:53:30+00:00</td>\n",
       "      <td>@JenniferCuriel9 @ClaudioXGG La MEGAMARCHA ğŸ‘‡ğŸ˜\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nakauma_takeshi</td>\n",
       "      <td>2022-11-16 19:52:37+00:00</td>\n",
       "      <td>@_VicenteSerrano @lopezobrador_ ğŸ˜‚ğŸ˜‚ğŸ˜‚ doliÃ³??? #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ToaFeliz3</td>\n",
       "      <td>2022-11-16 19:51:34+00:00</td>\n",
       "      <td>@Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jcquiroz21</td>\n",
       "      <td>2022-11-16 19:51:15+00:00</td>\n",
       "      <td>@EmilioAlvarezI El PRI de los 70â€™s ha vuelto. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                      date  \\\n",
       "0   sra_hofstadter 2022-11-16 19:53:34+00:00   \n",
       "1       MatthiVerg 2022-11-16 19:53:30+00:00   \n",
       "2  nakauma_takeshi 2022-11-16 19:52:37+00:00   \n",
       "3        ToaFeliz3 2022-11-16 19:51:34+00:00   \n",
       "4       jcquiroz21 2022-11-16 19:51:15+00:00   \n",
       "\n",
       "                                               tweet  \n",
       "0  @EugeniaLeon Hay sra. Si de por sÃ­ me daba flo...  \n",
       "1  @JenniferCuriel9 @ClaudioXGG La MEGAMARCHA ğŸ‘‡ğŸ˜\\...  \n",
       "2  @_VicenteSerrano @lopezobrador_ ğŸ˜‚ğŸ˜‚ğŸ˜‚ doliÃ³??? #...  \n",
       "3  @Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...  \n",
       "4  @EmilioAlvarezI El PRI de los 70â€™s ha vuelto. ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# asÃ­ se ve la base de datos\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-85f15d0b2b2e>:2: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "  df.describe()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>586</td>\n",
       "      <td>980</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>pao_maldo</td>\n",
       "      <td>2022-11-16 19:43:39+00:00</td>\n",
       "      <td>@mexico_rx @MaxKaiser75 @sylbeltrones @CarlosA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-16 13:46:44+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-16 19:53:34+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         username                       date  \\\n",
       "count        1000                       1000   \n",
       "unique        586                        980   \n",
       "top     pao_maldo  2022-11-16 19:43:39+00:00   \n",
       "freq           30                          2   \n",
       "first         NaN  2022-11-16 13:46:44+00:00   \n",
       "last          NaN  2022-11-16 19:53:34+00:00   \n",
       "\n",
       "                                                    tweet  \n",
       "count                                                1000  \n",
       "unique                                                998  \n",
       "top     @mexico_rx @MaxKaiser75 @sylbeltrones @CarlosA...  \n",
       "freq                                                    2  \n",
       "first                                                 NaN  \n",
       "last                                                  NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# descripciÃ³n general de los datos\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username    586\n",
       "date        980\n",
       "tweet       998\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identificaciÃ³n de valores Ãºnicos por variable\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminar signos de puntuaciÃ³n\n",
    "AquÃ­ se eliminan los signos de puntuaciÃ³n con excepciÃ³n de `#` para poder identificar los hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#library that contains punctuation\n",
    "import string\n",
    "signos_puntuacion = string.punctuation\n",
    "signos_puntuacion = signos_puntuacion.replace(\"#\", \"\")  # quitar '#' de hashtags \n",
    "signos_puntuacion = signos_puntuacion.replace(\"@\", \"\")  # quitar '@' de cuentas\n",
    "signos_puntuacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sra_hofstadter</td>\n",
       "      <td>2022-11-16 19:53:34+00:00</td>\n",
       "      <td>@EugeniaLeon Hay sra. Si de por sÃ­ me daba flo...</td>\n",
       "      <td>@EugeniaLeon Hay sra Si de por sÃ­ me daba floj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MatthiVerg</td>\n",
       "      <td>2022-11-16 19:53:30+00:00</td>\n",
       "      <td>@JenniferCuriel9 @ClaudioXGG La MEGAMARCHA ğŸ‘‡ğŸ˜\\...</td>\n",
       "      <td>@JenniferCuriel9 @ClaudioXGG La MEGAMARCHA ğŸ‘‡ğŸ˜\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nakauma_takeshi</td>\n",
       "      <td>2022-11-16 19:52:37+00:00</td>\n",
       "      <td>@_VicenteSerrano @lopezobrador_ ğŸ˜‚ğŸ˜‚ğŸ˜‚ doliÃ³??? #...</td>\n",
       "      <td>@VicenteSerrano @lopezobrador ğŸ˜‚ğŸ˜‚ğŸ˜‚ doliÃ³ #ElINE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ToaFeliz3</td>\n",
       "      <td>2022-11-16 19:51:34+00:00</td>\n",
       "      <td>@Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...</td>\n",
       "      <td>@Amadoelquelolea @SCJN Muy de acuerdo  \\nYo si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jcquiroz21</td>\n",
       "      <td>2022-11-16 19:51:15+00:00</td>\n",
       "      <td>@EmilioAlvarezI El PRI de los 70â€™s ha vuelto. ...</td>\n",
       "      <td>@EmilioAlvarezI El PRI de los 70â€™s ha vuelto \\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                      date  \\\n",
       "0   sra_hofstadter 2022-11-16 19:53:34+00:00   \n",
       "1       MatthiVerg 2022-11-16 19:53:30+00:00   \n",
       "2  nakauma_takeshi 2022-11-16 19:52:37+00:00   \n",
       "3        ToaFeliz3 2022-11-16 19:51:34+00:00   \n",
       "4       jcquiroz21 2022-11-16 19:51:15+00:00   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  @EugeniaLeon Hay sra. Si de por sÃ­ me daba flo...   \n",
       "1  @JenniferCuriel9 @ClaudioXGG La MEGAMARCHA ğŸ‘‡ğŸ˜\\...   \n",
       "2  @_VicenteSerrano @lopezobrador_ ğŸ˜‚ğŸ˜‚ğŸ˜‚ doliÃ³??? #...   \n",
       "3  @Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...   \n",
       "4  @EmilioAlvarezI El PRI de los 70â€™s ha vuelto. ...   \n",
       "\n",
       "                                         tweet_clean  \n",
       "0  @EugeniaLeon Hay sra Si de por sÃ­ me daba floj...  \n",
       "1  @JenniferCuriel9 @ClaudioXGG La MEGAMARCHA ğŸ‘‡ğŸ˜\\...  \n",
       "2  @VicenteSerrano @lopezobrador ğŸ˜‚ğŸ˜‚ğŸ˜‚ doliÃ³ #ElINE...  \n",
       "3  @Amadoelquelolea @SCJN Muy de acuerdo  \\nYo si...  \n",
       "4  @EmilioAlvarezI El PRI de los 70â€™s ha vuelto \\...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining the function to remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in signos_puntuacion])\n",
    "    return punctuationfree\n",
    "\n",
    "#storing the puntuation free text\n",
    "df['tweet_clean'] = df['tweet'].apply(lambda x:remove_punctuation(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Textos en minÃºsculas\n",
    "Parte de la normalizaciÃ³n es poner todos los textos en minÃºsculas (o mayÃºsculas), esto puede servir posteriormente por ejemplo para hacer un conteo de palabras.\n",
    "\n",
    "âš ï¸ _**Nota**: Al hacer esto existe el riesgo que se pierda informaciÃ³n contextual; por ejemplo, dentro de un tweet cuando alguien escribe una palabra especÃ­fica en mayÃºsculas y las demÃ¡s en minÃºsculas esto conlleva un mayor importancia o aumento en tono de voz._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sra_hofstadter</td>\n",
       "      <td>2022-11-16 19:53:34+00:00</td>\n",
       "      <td>@EugeniaLeon Hay sra. Si de por sÃ­ me daba flo...</td>\n",
       "      <td>@eugenialeon hay sra si de por sÃ­ me daba floj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MatthiVerg</td>\n",
       "      <td>2022-11-16 19:53:30+00:00</td>\n",
       "      <td>@JenniferCuriel9 @ClaudioXGG La MEGAMARCHA ğŸ‘‡ğŸ˜\\...</td>\n",
       "      <td>@jennifercuriel9 @claudioxgg la megamarcha ğŸ‘‡ğŸ˜\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nakauma_takeshi</td>\n",
       "      <td>2022-11-16 19:52:37+00:00</td>\n",
       "      <td>@_VicenteSerrano @lopezobrador_ ğŸ˜‚ğŸ˜‚ğŸ˜‚ doliÃ³??? #...</td>\n",
       "      <td>@vicenteserrano @lopezobrador ğŸ˜‚ğŸ˜‚ğŸ˜‚ doliÃ³ #eline...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ToaFeliz3</td>\n",
       "      <td>2022-11-16 19:51:34+00:00</td>\n",
       "      <td>@Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...</td>\n",
       "      <td>@amadoelquelolea @scjn muy de acuerdo  \\nyo si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jcquiroz21</td>\n",
       "      <td>2022-11-16 19:51:15+00:00</td>\n",
       "      <td>@EmilioAlvarezI El PRI de los 70â€™s ha vuelto. ...</td>\n",
       "      <td>@emilioalvarezi el pri de los 70â€™s ha vuelto \\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                      date  \\\n",
       "0   sra_hofstadter 2022-11-16 19:53:34+00:00   \n",
       "1       MatthiVerg 2022-11-16 19:53:30+00:00   \n",
       "2  nakauma_takeshi 2022-11-16 19:52:37+00:00   \n",
       "3        ToaFeliz3 2022-11-16 19:51:34+00:00   \n",
       "4       jcquiroz21 2022-11-16 19:51:15+00:00   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  @EugeniaLeon Hay sra. Si de por sÃ­ me daba flo...   \n",
       "1  @JenniferCuriel9 @ClaudioXGG La MEGAMARCHA ğŸ‘‡ğŸ˜\\...   \n",
       "2  @_VicenteSerrano @lopezobrador_ ğŸ˜‚ğŸ˜‚ğŸ˜‚ doliÃ³??? #...   \n",
       "3  @Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...   \n",
       "4  @EmilioAlvarezI El PRI de los 70â€™s ha vuelto. ...   \n",
       "\n",
       "                                         tweet_clean  \n",
       "0  @eugenialeon hay sra si de por sÃ­ me daba floj...  \n",
       "1  @jennifercuriel9 @claudioxgg la megamarcha ğŸ‘‡ğŸ˜\\...  \n",
       "2  @vicenteserrano @lopezobrador ğŸ˜‚ğŸ˜‚ğŸ˜‚ doliÃ³ #eline...  \n",
       "3  @amadoelquelolea @scjn muy de acuerdo  \\nyo si...  \n",
       "4  @emilioalvarezi el pri de los 70â€™s ha vuelto \\...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cambiar los tweets a letras minÃºsculas\n",
    "df['tweet_clean'] = df['tweet_clean'].apply((lambda x: x.lower()))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "AquÃ­ veremos cÃ³mo separar los enunciados (*tweets*) en *tokens* (palabras o cadenas de caracteres)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sra_hofstadter</td>\n",
       "      <td>2022-11-16 19:53:34+00:00</td>\n",
       "      <td>@EugeniaLeon Hay sra. Si de por sÃ­ me daba flo...</td>\n",
       "      <td>[@eugenialeon, hay, sra, si, de, por, sÃ­, me, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MatthiVerg</td>\n",
       "      <td>2022-11-16 19:53:30+00:00</td>\n",
       "      <td>@JenniferCuriel9 @ClaudioXGG La MEGAMARCHA ğŸ‘‡ğŸ˜\\...</td>\n",
       "      <td>[@jennifercuriel9, @claudioxgg, la, megamarcha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nakauma_takeshi</td>\n",
       "      <td>2022-11-16 19:52:37+00:00</td>\n",
       "      <td>@_VicenteSerrano @lopezobrador_ ğŸ˜‚ğŸ˜‚ğŸ˜‚ doliÃ³??? #...</td>\n",
       "      <td>[@vicenteserrano, @lopezobrador, ğŸ˜‚ğŸ˜‚ğŸ˜‚, doliÃ³, #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ToaFeliz3</td>\n",
       "      <td>2022-11-16 19:51:34+00:00</td>\n",
       "      <td>@Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...</td>\n",
       "      <td>[@amadoelquelolea, @scjn, muy, de, acuerdo, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jcquiroz21</td>\n",
       "      <td>2022-11-16 19:51:15+00:00</td>\n",
       "      <td>@EmilioAlvarezI El PRI de los 70â€™s ha vuelto. ...</td>\n",
       "      <td>[@emilioalvarezi, el, pri, de, los, 70â€™s, ha, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                      date  \\\n",
       "0   sra_hofstadter 2022-11-16 19:53:34+00:00   \n",
       "1       MatthiVerg 2022-11-16 19:53:30+00:00   \n",
       "2  nakauma_takeshi 2022-11-16 19:52:37+00:00   \n",
       "3        ToaFeliz3 2022-11-16 19:51:34+00:00   \n",
       "4       jcquiroz21 2022-11-16 19:51:15+00:00   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  @EugeniaLeon Hay sra. Si de por sÃ­ me daba flo...   \n",
       "1  @JenniferCuriel9 @ClaudioXGG La MEGAMARCHA ğŸ‘‡ğŸ˜\\...   \n",
       "2  @_VicenteSerrano @lopezobrador_ ğŸ˜‚ğŸ˜‚ğŸ˜‚ doliÃ³??? #...   \n",
       "3  @Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...   \n",
       "4  @EmilioAlvarezI El PRI de los 70â€™s ha vuelto. ...   \n",
       "\n",
       "                                         tweet_clean  \n",
       "0  [@eugenialeon, hay, sra, si, de, por, sÃ­, me, ...  \n",
       "1  [@jennifercuriel9, @claudioxgg, la, megamarcha...  \n",
       "2  [@vicenteserrano, @lopezobrador, ğŸ˜‚ğŸ˜‚ğŸ˜‚, doliÃ³, #...  \n",
       "3  [@amadoelquelolea, @scjn, muy, de, acuerdo, yo...  \n",
       "4  [@emilioalvarezi, el, pri, de, los, 70â€™s, ha, ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the tokens per tweet\n",
    "df['tweet_clean'] = df['tweet_clean'].apply(lambda x: x.rsplit())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminar *stopwords*\n",
    "Las *stopwords* son palabras de uso comÃºn que no aÃ±aden un valor adicional al anÃ¡lisis de texto o que no tienen sentido, por lo que pueden ser eliminadas de nuestra lista de tokens.\n",
    "\n",
    "Existen distintas maneras de obtener la lista de stopwords:  \n",
    "> (1) Crear nuestra propia lista  \n",
    "\n",
    "> (2) Buscar alguna base de datos que contenga la lista de stopwords\n",
    "> - En GitHub encontrÃ© una lista de stopwords el el repositorio [Alir3z4/stop-words](https://github.com/Alir3z4/stop-words/blob/master/spanish.txt)\n",
    "> - Una alternativa es una lista de Kaggle [Spanish Stopwords W2V](https://www.kaggle.com/code/mpwolke/spanish-stopwords-w2v)\n",
    "> - Otra alternativa es la lista que da la pÃ¡gina [countwordsfree.com](https://countwordsfree.com/stopwords/spanish)\n",
    "\n",
    "> (3) Algo mÃ¡s estandarizado y completo es utilizar la librerÃ­a de *Natural Language Toolkit* (**NLTK**), la cual tiene listas de stopwords en distintos idiomas, donde (ademÃ¡s de inglÃ©s) podemos encontrar la lista de palabras en espaÃ±ol. Para instalar este paquete asÃ­ como mayor detalle de uso, revisa la pÃ¡gina de la [librerÃ­a NLTK](https://www.nltk.org/data.html).\n",
    "\n",
    "âš ï¸ _**Nota**: antes de usar alguna de las opciones anteriores deberÃ¡s de pensar cuÃ¡l lista de stopwords se acopla mejor a tus necesidades!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NÃºmero de stopwords en mi lista (1): 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a', 'ante', 'bajo', 'cabe', 'con', 'no', 'de', 'del', 'al', 'tras']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (1) Crear nuestra propia lista de stopwords\n",
    "stopwords_1 = ['a','ante','bajo','cabe','con','no','de','del','al','tras']\n",
    "\n",
    "print(\"NÃºmero de stopwords en mi lista (1):\", len(stopwords_1))\n",
    "stopwords_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NÃºmero de stopwords en mi lista (2): 609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'actualmente',\n",
       " 'adelante',\n",
       " 'ademÃ¡s',\n",
       " 'afirmÃ³',\n",
       " 'agregÃ³',\n",
       " 'ahora',\n",
       " 'ahÃ­',\n",
       " 'al',\n",
       " 'algo',\n",
       " 'alguna',\n",
       " 'algunas',\n",
       " 'alguno',\n",
       " 'algunos',\n",
       " 'algÃºn']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (2) Buscar alguna base de datos que contenga la lista de stopwords.\n",
    "#     En este ejemplo bajamos la lista de GitHub\n",
    "import urllib3\n",
    "\n",
    "http = urllib3.PoolManager()\n",
    "r = http.request('GET', \"https://raw.githubusercontent.com/Alir3z4/stop-words/master/spanish.txt\")\n",
    "stopwords_2 = r.data.decode('utf-8').replace(\"\\n\",\" \").rsplit()\n",
    "\n",
    "print(\"NÃºmero de stopwords en mi lista (2):\", len(stopwords_2))\n",
    "stopwords_2[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NÃºmero de stopwords en de NLTK library (3): 313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['de',\n",
       " 'la',\n",
       " 'que',\n",
       " 'el',\n",
       " 'en',\n",
       " 'y',\n",
       " 'a',\n",
       " 'los',\n",
       " 'del',\n",
       " 'se',\n",
       " 'las',\n",
       " 'por',\n",
       " 'un',\n",
       " 'para',\n",
       " 'con']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (3) Uso de NLP Toolkit library\n",
    "\n",
    "## Para instalar la librerÃ­a revisa la pÃ¡gina: https://www.nltk.org/data.html\n",
    "## Nota, este proceso puede ser tardado...\n",
    "# !pip install nltk\n",
    "# nltk.download()\n",
    "\n",
    "# load library\n",
    "import nltk\n",
    "\n",
    "stopwords_3 = nltk.corpus.stopwords.words('spanish')\n",
    "\n",
    "print(\"NÃºmero de stopwords en de NLTK library (3):\", len(stopwords_3))\n",
    "stopwords_3[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vamos a eliminar las stopwords usando la lista que obtivimos de NLTK library (opciÃ³n 3):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sra_hofstadter</td>\n",
       "      <td>2022-11-16 19:53:34+00:00</td>\n",
       "      <td>@EugeniaLeon Hay sra. Si de por sÃ­ me daba flo...</td>\n",
       "      <td>[@eugenialeon, sra, si, daba, flojera, ahora, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MatthiVerg</td>\n",
       "      <td>2022-11-16 19:53:30+00:00</td>\n",
       "      <td>@JenniferCuriel9 @ClaudioXGG La MEGAMARCHA ğŸ‘‡ğŸ˜\\...</td>\n",
       "      <td>[@jennifercuriel9, @claudioxgg, megamarcha, ğŸ‘‡ğŸ˜...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nakauma_takeshi</td>\n",
       "      <td>2022-11-16 19:52:37+00:00</td>\n",
       "      <td>@_VicenteSerrano @lopezobrador_ ğŸ˜‚ğŸ˜‚ğŸ˜‚ doliÃ³??? #...</td>\n",
       "      <td>[@vicenteserrano, @lopezobrador, ğŸ˜‚ğŸ˜‚ğŸ˜‚, doliÃ³, #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ToaFeliz3</td>\n",
       "      <td>2022-11-16 19:51:34+00:00</td>\n",
       "      <td>@Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...</td>\n",
       "      <td>[@amadoelquelolea, @scjn, acuerdo, si, voy, vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jcquiroz21</td>\n",
       "      <td>2022-11-16 19:51:15+00:00</td>\n",
       "      <td>@EmilioAlvarezI El PRI de los 70â€™s ha vuelto. ...</td>\n",
       "      <td>[@emilioalvarezi, pri, 70â€™s, vuelto, @lopezobr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                      date  \\\n",
       "0   sra_hofstadter 2022-11-16 19:53:34+00:00   \n",
       "1       MatthiVerg 2022-11-16 19:53:30+00:00   \n",
       "2  nakauma_takeshi 2022-11-16 19:52:37+00:00   \n",
       "3        ToaFeliz3 2022-11-16 19:51:34+00:00   \n",
       "4       jcquiroz21 2022-11-16 19:51:15+00:00   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  @EugeniaLeon Hay sra. Si de por sÃ­ me daba flo...   \n",
       "1  @JenniferCuriel9 @ClaudioXGG La MEGAMARCHA ğŸ‘‡ğŸ˜\\...   \n",
       "2  @_VicenteSerrano @lopezobrador_ ğŸ˜‚ğŸ˜‚ğŸ˜‚ doliÃ³??? #...   \n",
       "3  @Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...   \n",
       "4  @EmilioAlvarezI El PRI de los 70â€™s ha vuelto. ...   \n",
       "\n",
       "                                         tweet_clean  \n",
       "0  [@eugenialeon, sra, si, daba, flojera, ahora, ...  \n",
       "1  [@jennifercuriel9, @claudioxgg, megamarcha, ğŸ‘‡ğŸ˜...  \n",
       "2  [@vicenteserrano, @lopezobrador, ğŸ˜‚ğŸ˜‚ğŸ˜‚, doliÃ³, #...  \n",
       "3  [@amadoelquelolea, @scjn, acuerdo, si, voy, vi...  \n",
       "4  [@emilioalvarezi, pri, 70â€™s, vuelto, @lopezobr...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining the function to remove stopwords from tokenized text\n",
    "def remove_stopwords(text):\n",
    "    output= [i for i in text if i not in stopwords_3]\n",
    "    return output\n",
    "\n",
    "#applying the stopwords function to thet tweets\n",
    "df['tweet_clean'] = df['tweet_clean'].apply(lambda x:remove_stopwords(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LematizaciÃ³n\n",
    "Este paso nos servirÃ¡ para extraer la la raÃ­z de las palabras, para poder \"normalizar\" el texto y realizar un mejor anÃ¡lisis. AquÃ­ nuevamente utilizaremos la librerÃ­a `NLTK`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sra_hofstadter</td>\n",
       "      <td>2022-11-16 19:53:34+00:00</td>\n",
       "      <td>@EugeniaLeon Hay sra. Si de por sÃ­ me daba flo...</td>\n",
       "      <td>[@eugenialeon, sra, si, daba, flojera, ahora, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MatthiVerg</td>\n",
       "      <td>2022-11-16 19:53:30+00:00</td>\n",
       "      <td>@JenniferCuriel9 @ClaudioXGG La MEGAMARCHA ğŸ‘‡ğŸ˜\\...</td>\n",
       "      <td>[@jennifercuriel9, @claudioxgg, megamarcha, ğŸ‘‡ğŸ˜...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nakauma_takeshi</td>\n",
       "      <td>2022-11-16 19:52:37+00:00</td>\n",
       "      <td>@_VicenteSerrano @lopezobrador_ ğŸ˜‚ğŸ˜‚ğŸ˜‚ doliÃ³??? #...</td>\n",
       "      <td>[@vicenteserrano, @lopezobrador, ğŸ˜‚ğŸ˜‚ğŸ˜‚, doliÃ³, #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ToaFeliz3</td>\n",
       "      <td>2022-11-16 19:51:34+00:00</td>\n",
       "      <td>@Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...</td>\n",
       "      <td>[@amadoelquelolea, @scjn, acuerdo, si, voy, vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jcquiroz21</td>\n",
       "      <td>2022-11-16 19:51:15+00:00</td>\n",
       "      <td>@EmilioAlvarezI El PRI de los 70â€™s ha vuelto. ...</td>\n",
       "      <td>[@emilioalvarezi, pri, 70â€™s, vuelto, @lopezobr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                      date  \\\n",
       "0   sra_hofstadter 2022-11-16 19:53:34+00:00   \n",
       "1       MatthiVerg 2022-11-16 19:53:30+00:00   \n",
       "2  nakauma_takeshi 2022-11-16 19:52:37+00:00   \n",
       "3        ToaFeliz3 2022-11-16 19:51:34+00:00   \n",
       "4       jcquiroz21 2022-11-16 19:51:15+00:00   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  @EugeniaLeon Hay sra. Si de por sÃ­ me daba flo...   \n",
       "1  @JenniferCuriel9 @ClaudioXGG La MEGAMARCHA ğŸ‘‡ğŸ˜\\...   \n",
       "2  @_VicenteSerrano @lopezobrador_ ğŸ˜‚ğŸ˜‚ğŸ˜‚ doliÃ³??? #...   \n",
       "3  @Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...   \n",
       "4  @EmilioAlvarezI El PRI de los 70â€™s ha vuelto. ...   \n",
       "\n",
       "                                         tweet_clean  \n",
       "0  [@eugenialeon, sra, si, daba, flojera, ahora, ...  \n",
       "1  [@jennifercuriel9, @claudioxgg, megamarcha, ğŸ‘‡ğŸ˜...  \n",
       "2  [@vicenteserrano, @lopezobrador, ğŸ˜‚ğŸ˜‚ğŸ˜‚, doliÃ³, #...  \n",
       "3  [@amadoelquelolea, @scjn, acuerdo, si, voy, vi...  \n",
       "4  [@emilioalvarezi, pri, 70â€™s, vuelto, @lopezobr...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining the object for Lemmatization\n",
    "wordnet_lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "#defining the function for lemmatization\n",
    "def lemmatizer(text):\n",
    "    lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
    "    return lemm_text\n",
    "\n",
    "#lemmatization of our tweets\n",
    "df['tweet_clean'] = df['tweet_clean'].apply(lambda x:lemmatizer(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminar URLs\n",
    "En este caso, tambiÃ©n eliminamos las URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sra_hofstadter</td>\n",
       "      <td>2022-11-16 19:53:34+00:00</td>\n",
       "      <td>@EugeniaLeon Hay sra. Si de por sÃ­ me daba flo...</td>\n",
       "      <td>[@eugenialeon, sra, si, daba, flojera, ahora, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MatthiVerg</td>\n",
       "      <td>2022-11-16 19:53:30+00:00</td>\n",
       "      <td>@JenniferCuriel9 @ClaudioXGG La MEGAMARCHA ğŸ‘‡ğŸ˜\\...</td>\n",
       "      <td>[@jennifercuriel9, @claudioxgg, megamarcha, ğŸ‘‡ğŸ˜...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nakauma_takeshi</td>\n",
       "      <td>2022-11-16 19:52:37+00:00</td>\n",
       "      <td>@_VicenteSerrano @lopezobrador_ ğŸ˜‚ğŸ˜‚ğŸ˜‚ doliÃ³??? #...</td>\n",
       "      <td>[@vicenteserrano, @lopezobrador, ğŸ˜‚ğŸ˜‚ğŸ˜‚, doliÃ³, #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ToaFeliz3</td>\n",
       "      <td>2022-11-16 19:51:34+00:00</td>\n",
       "      <td>@Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...</td>\n",
       "      <td>[@amadoelquelolea, @scjn, acuerdo, si, voy, vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jcquiroz21</td>\n",
       "      <td>2022-11-16 19:51:15+00:00</td>\n",
       "      <td>@EmilioAlvarezI El PRI de los 70â€™s ha vuelto. ...</td>\n",
       "      <td>[@emilioalvarezi, pri, 70â€™s, vuelto, @lopezobr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username                      date  \\\n",
       "0   sra_hofstadter 2022-11-16 19:53:34+00:00   \n",
       "1       MatthiVerg 2022-11-16 19:53:30+00:00   \n",
       "2  nakauma_takeshi 2022-11-16 19:52:37+00:00   \n",
       "3        ToaFeliz3 2022-11-16 19:51:34+00:00   \n",
       "4       jcquiroz21 2022-11-16 19:51:15+00:00   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  @EugeniaLeon Hay sra. Si de por sÃ­ me daba flo...   \n",
       "1  @JenniferCuriel9 @ClaudioXGG La MEGAMARCHA ğŸ‘‡ğŸ˜\\...   \n",
       "2  @_VicenteSerrano @lopezobrador_ ğŸ˜‚ğŸ˜‚ğŸ˜‚ doliÃ³??? #...   \n",
       "3  @Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...   \n",
       "4  @EmilioAlvarezI El PRI de los 70â€™s ha vuelto. ...   \n",
       "\n",
       "                                         tweet_clean  \n",
       "0  [@eugenialeon, sra, si, daba, flojera, ahora, ...  \n",
       "1  [@jennifercuriel9, @claudioxgg, megamarcha, ğŸ‘‡ğŸ˜...  \n",
       "2  [@vicenteserrano, @lopezobrador, ğŸ˜‚ğŸ˜‚ğŸ˜‚, doliÃ³, #...  \n",
       "3  [@amadoelquelolea, @scjn, acuerdo, si, voy, vi...  \n",
       "4  [@emilioalvarezi, pri, 70â€™s, vuelto, @lopezobr...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def erase_urls(text):\n",
    "    output = [i for i in text if i.rfind(\"http\")==-1]\n",
    "    return output\n",
    "\n",
    "# texto.rfind(\"villano\")\n",
    "df['tweet_clean'] = df['tweet_clean'].apply(lambda x:erase_urls(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado final de preproceso (BD final)\n",
    "A continuaciÃ³n se muestran los textos iniciales en la columna \"tweets\", y la informaciÃ³n preprocesada en la columna \"tweet_clean\", a manera de comparaciÃ³n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@EugeniaLeon Hay sra. Si de por sÃ­ me daba flo...</td>\n",
       "      <td>[@eugenialeon, sra, si, daba, flojera, ahora, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@JenniferCuriel9 @ClaudioXGG La MEGAMARCHA ğŸ‘‡ğŸ˜\\...</td>\n",
       "      <td>[@jennifercuriel9, @claudioxgg, megamarcha, ğŸ‘‡ğŸ˜...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@_VicenteSerrano @lopezobrador_ ğŸ˜‚ğŸ˜‚ğŸ˜‚ doliÃ³??? #...</td>\n",
       "      <td>[@vicenteserrano, @lopezobrador, ğŸ˜‚ğŸ˜‚ğŸ˜‚, doliÃ³, #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...</td>\n",
       "      <td>[@amadoelquelolea, @scjn, acuerdo, si, voy, vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@EmilioAlvarezI El PRI de los 70â€™s ha vuelto. ...</td>\n",
       "      <td>[@emilioalvarezi, pri, 70â€™s, vuelto, @lopezobr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Verdad que si lo quieren desaparecer?\\nSÃ³lo lo...</td>\n",
       "      <td>[verdad, si, quieren, desaparecer, sÃ³lo, abyec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>@lopezobrador_ Y AMLO en vez de gobernar, sale...</td>\n",
       "      <td>[@lopezobrador, amlo, vez, gobernar, sale, des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Lo Ãºnico que saben es robar, mentir y destruir...</td>\n",
       "      <td>[Ãºnico, saben, robar, mentir, destruir, #moren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>@EugeniaLeon @lopezobrador_ #ElINENoSeToca \\n#...</td>\n",
       "      <td>[@eugenialeon, @lopezobrador, #elinenosetoca, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>@santiagobaeza @lopezobrador_ la gente se hart...</td>\n",
       "      <td>[@santiagobaeza, @lopezobrador, gente, hartÃ³, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet  \\\n",
       "0    @EugeniaLeon Hay sra. Si de por sÃ­ me daba flo...   \n",
       "1    @JenniferCuriel9 @ClaudioXGG La MEGAMARCHA ğŸ‘‡ğŸ˜\\...   \n",
       "2    @_VicenteSerrano @lopezobrador_ ğŸ˜‚ğŸ˜‚ğŸ˜‚ doliÃ³??? #...   \n",
       "3    @Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...   \n",
       "4    @EmilioAlvarezI El PRI de los 70â€™s ha vuelto. ...   \n",
       "..                                                 ...   \n",
       "995  Verdad que si lo quieren desaparecer?\\nSÃ³lo lo...   \n",
       "996  @lopezobrador_ Y AMLO en vez de gobernar, sale...   \n",
       "997  Lo Ãºnico que saben es robar, mentir y destruir...   \n",
       "998  @EugeniaLeon @lopezobrador_ #ElINENoSeToca \\n#...   \n",
       "999  @santiagobaeza @lopezobrador_ la gente se hart...   \n",
       "\n",
       "                                           tweet_clean  \n",
       "0    [@eugenialeon, sra, si, daba, flojera, ahora, ...  \n",
       "1    [@jennifercuriel9, @claudioxgg, megamarcha, ğŸ‘‡ğŸ˜...  \n",
       "2    [@vicenteserrano, @lopezobrador, ğŸ˜‚ğŸ˜‚ğŸ˜‚, doliÃ³, #...  \n",
       "3    [@amadoelquelolea, @scjn, acuerdo, si, voy, vi...  \n",
       "4    [@emilioalvarezi, pri, 70â€™s, vuelto, @lopezobr...  \n",
       "..                                                 ...  \n",
       "995  [verdad, si, quieren, desaparecer, sÃ³lo, abyec...  \n",
       "996  [@lopezobrador, amlo, vez, gobernar, sale, des...  \n",
       "997  [Ãºnico, saben, robar, mentir, destruir, #moren...  \n",
       "998  [@eugenialeon, @lopezobrador, #elinenosetoca, ...  \n",
       "999  [@santiagobaeza, @lopezobrador, gente, hartÃ³, ...  \n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['tweet', 'tweet_clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo de tweet...\n",
      "- original tweet:\n",
      " @JenniferCuriel9 @ClaudioXGG La MEGAMARCHA ğŸ‘‡ğŸ˜\n",
      "#ElINENoSeToca https://t.co/rJnuVP12US \n",
      "\n",
      "- tweet clean:\n",
      " ['@jennifercuriel9', '@claudioxgg', 'megamarcha', 'ğŸ‘‡ğŸ˜', '#elinenosetoca']\n"
     ]
    }
   ],
   "source": [
    "print(\"Ejemplo de tweet...\\n- original tweet:\\n\",df['tweet'][1],\n",
    "      \"\\n\\n- tweet clean:\\n\", df['tweet_clean'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Regular expressions (*Regex*)\n",
    "Las expresiones regulares mejor conocidas como *regex* son una herramienta que nos sirve para trabajar con texto, con el cual se pueden realziar distintas operaciones como bÃºsqueda o reemplazo de un texto especÃ­fico.\n",
    "\n",
    "Existen distintos operadores que se utilizan en *regex*, estos son los que utilizaremos para nuestros ejemplos. \n",
    "\n",
    "\n",
    "|Operador|DescripciÃ³n (_en inglÃ©s_)|\n",
    "|:------:|:----------------------|\n",
    "|. (punto)|In the default mode, this matches any character except a newline. If the DOTALL flag has been specified, this matches any character including a newline.|\n",
    "|* (asterisco) |Causes the resulting RE to match 0 or more repetitions of the preceding RE, as many repetitions as are possible. ab* will match â€˜aâ€™, â€˜abâ€™, or â€˜aâ€™ followed by any number of â€˜bâ€™s.|\n",
    "|+ (mÃ¡s) |Causes the resulting RE to match 1 or more repetitions of the preceding RE. ab+ will match â€˜aâ€™ followed by any non-zero number of â€˜bâ€™s; it will not match just â€˜aâ€™.|\n",
    "|[ ]| Used to indicate a set of characters. In a set:<ul><li>Characters can be listed individually, e.g. [amk] will match 'a', 'm', or 'k'.</li><li>Ranges of characters can be indicated by giving two characters and separating them by a '-', for example [a-z] will match any lowercase ASCII letter, [0-5][0-9] will match all the two-digits numbers from 00 to 59, and [0-9A-Fa-f] will match any hexadecimal digit. If - is escaped (e.g. [a\\-z]) or if itâ€™s placed as the first or last character (e.g. [-a] or [a-]), it will match a literal '-'.</li><li>Special characters lose their special meaning inside sets. For example, [(+*)] will match any of the literal characters '(', '+', '*', or ')'.</li></ul>|\n",
    "|\\n |line break|\n",
    "\n",
    "âš ï¸ Se recomienda ampliamente que revisen la pÃ¡gina de la [librerÃ­a **`re`** - *Regular expression operations*](https://docs.python.org/3/library/re.html) para identificar todos los operadores, documentaciÃ³n y ejemplos de como utilizar _regex_.\n",
    "\n",
    "ğŸ“Œ Si les interesa practicar el uso de _regex_, les recomiendo la pÃ¡gina de [regexr.com](https://regexr.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load regex library\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracto de canciÃ³n \"El amor\" de Arjona, link: https://www.letras.com/arjona-ricardo/1963651/\n",
    "texto = \"\"\"El amor tiene firma de autor\n",
    "En las causas pÃ©rdidas\n",
    "El amor siempre empieza soÃ±ando\n",
    "Y termina en insomnio\n",
    "Es un acto profundo de fe\n",
    "Que huele a mentira\n",
    "El amor baila al son que le toquen\n",
    "Sea Dios o el demonio\n",
    "Sea Dios o el demonio\n",
    "\n",
    "El amor es la guerra pÃ©rdida\n",
    "Entre el sexo y la risa\n",
    "Es la llave con que abres\n",
    "El grifo del agua en los ojos\n",
    "Es el tiempo mÃ¡s lento del mundo\n",
    "Cuando va de prisa\n",
    "El amor se abre paso despacio\n",
    "No importa el cerrojo\n",
    "\n",
    "El amor es la arrogancia\n",
    "De aferrarse a lo imposible\n",
    "Es buscar en otra parte\n",
    "Lo que no encuentras en ti\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encontrar un texto usando _regex_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['El amor tiene firma de autor',\n",
       " 'El amor siempre empieza soÃ±ando',\n",
       " 'El amor baila al son que le toquen',\n",
       " 'El amor es la guerra pÃ©rdida',\n",
       " 'El amor se abre paso despacio',\n",
       " 'El amor es la arrogancia']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encontrar todos los enunciados que tengan la palabra 'amor'\n",
    "re.findall(r'.*[A|a]mor.*', texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sustituir una palabra, frase o cadena de caracterÃ©s por otro texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El CePiLLo dE DiEnTeS tiene firma de autor. En las causas pÃ©rdidas. El CePiLLo dE DiEnTeS siempre empieza soÃ±ando. Y termina en insomnio. Es un acto profundo de fe. Que huele a mentira. El CePiLLo dE DiEnTeS baila al son que le toquen. Sea Dios o el demonio. Sea Dios o el demonio. El CePiLLo dE DiEnTeS es la guerra pÃ©rdida. Entre el sexo y la risa. Es la llave con que abres. El grifo del agua en los ojos. Es el tiempo mÃ¡s lento del mundo. Cuando va de prisa. El CePiLLo dE DiEnTeS se abre paso despacio. No importa el cerrojo. El CePiLLo dE DiEnTeS es la arrogancia. De aferrarse a lo imposible. Es buscar en otra parte. Lo que no encuentras en ti. '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Substituir la palabra 'amor' por 'cepillo de dientes'\n",
    "texto_sub = re.sub('[A|a]mor', 'CePiLLo dE DiEnTeS', texto)  # cambia la palabra\n",
    "texto_sub = re.sub('\\n+', '. ', texto_sub)  # cambia el salto de dos renglones por un punto \n",
    "texto_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividir el texto en una lista de strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['El amor tiene firma de autor',\n",
       " 'En las causas pÃ©rdidas',\n",
       " 'El amor siempre empieza soÃ±ando',\n",
       " 'Y termina en insomnio',\n",
       " 'Es un acto profundo de fe',\n",
       " 'Que huele a mentira',\n",
       " 'El amor baila al son que le toquen',\n",
       " 'Sea Dios o el demonio',\n",
       " 'Sea Dios o el demonio',\n",
       " 'El amor es la guerra pÃ©rdida',\n",
       " 'Entre el sexo y la risa',\n",
       " 'Es la llave con que abres',\n",
       " 'El grifo del agua en los ojos',\n",
       " 'Es el tiempo mÃ¡s lento del mundo',\n",
       " 'Cuando va de prisa',\n",
       " 'El amor se abre paso despacio',\n",
       " 'No importa el cerrojo',\n",
       " 'El amor es la arrogancia',\n",
       " 'De aferrarse a lo imposible',\n",
       " 'Es buscar en otra parte',\n",
       " 'Lo que no encuentras en ti',\n",
       " '']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(\"\\n+\", texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install spaCy webpage: https://spacy.io/usage\n",
    "# ! conda install -c conda-forge spacy  # <-install spaCy\n",
    "# ! python -m spacy download en_core_web_sm   # <-spaCy English pipeline optimized for CPU.\n",
    "# ! python -m spacy download es_core_news_sm  # <-spaCy Spanish pipeline optimized for CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load library\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtener caracterÃ­sticas de cada *token*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enunciado:\n",
      " Me llegÃ³ un email al correo leo234@gmail.com que dice: \"OMG! El seÃ±or Carlos rompiÃ³ el control del televisor hoy y tuve que comprar otro en www.amazon.com.mx\". \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>dep</th>\n",
       "      <th>is_email</th>\n",
       "      <th>is_url</th>\n",
       "      <th>next_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Me</td>\n",
       "      <td>yo</td>\n",
       "      <td>PRON</td>\n",
       "      <td>iobj</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>llegÃ³</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llegÃ³</td>\n",
       "      <td>llegar</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>llegÃ³</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>un</td>\n",
       "      <td>uno</td>\n",
       "      <td>DET</td>\n",
       "      <td>det</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>email</td>\n",
       "      <td>email</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>llegÃ³</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>al</td>\n",
       "      <td>al</td>\n",
       "      <td>ADP</td>\n",
       "      <td>case</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>correo</td>\n",
       "      <td>correo</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>obl</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>llegÃ³</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>leo234@gmail.com</td>\n",
       "      <td>leo234@gmail.com</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>appos</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>correo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>que</td>\n",
       "      <td>que</td>\n",
       "      <td>PRON</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>dice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dice</td>\n",
       "      <td>decir</td>\n",
       "      <td>VERB</td>\n",
       "      <td>csubj</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>llegÃ³</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>OMG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"</td>\n",
       "      <td>\"</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>OMG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OMG</td>\n",
       "      <td>OMG</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>obj</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>dice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>OMG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>El</td>\n",
       "      <td>el</td>\n",
       "      <td>DET</td>\n",
       "      <td>det</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>seÃ±or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>seÃ±or</td>\n",
       "      <td>seÃ±or</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>rompiÃ³</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Carlos</td>\n",
       "      <td>Carlos</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>appos</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>seÃ±or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rompiÃ³</td>\n",
       "      <td>romper</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>rompiÃ³</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>el</td>\n",
       "      <td>el</td>\n",
       "      <td>DET</td>\n",
       "      <td>det</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>control</td>\n",
       "      <td>control</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>obj</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>rompiÃ³</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>del</td>\n",
       "      <td>del</td>\n",
       "      <td>ADP</td>\n",
       "      <td>case</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>televisor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>televisor</td>\n",
       "      <td>televisor</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>hoy</td>\n",
       "      <td>hoy</td>\n",
       "      <td>ADV</td>\n",
       "      <td>advmod</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>rompiÃ³</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>cc</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>tuve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tuve</td>\n",
       "      <td>tener</td>\n",
       "      <td>VERB</td>\n",
       "      <td>conj</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>rompiÃ³</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>que</td>\n",
       "      <td>que</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>cc</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>comprar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>comprar</td>\n",
       "      <td>comprar</td>\n",
       "      <td>VERB</td>\n",
       "      <td>conj</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>tuve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>otro</td>\n",
       "      <td>otro</td>\n",
       "      <td>PRON</td>\n",
       "      <td>obj</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>comprar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>ADP</td>\n",
       "      <td>case</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>www.amazon.com.mx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>www.amazon.com.mx</td>\n",
       "      <td>www.amazon.com.mx</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>obl</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>comprar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\"</td>\n",
       "      <td>\"</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>rompiÃ³</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>rompiÃ³</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 text              lemma    pos     dep  is_email  is_url  \\\n",
       "0                  Me                 yo   PRON    iobj     False   False   \n",
       "1               llegÃ³             llegar   VERB    ROOT     False   False   \n",
       "2                  un                uno    DET     det     False   False   \n",
       "3               email              email   NOUN   nsubj     False   False   \n",
       "4                  al                 al    ADP    case     False   False   \n",
       "5              correo             correo   NOUN     obl     False   False   \n",
       "6    leo234@gmail.com   leo234@gmail.com  PROPN   appos      True   False   \n",
       "7                 que                que   PRON   nsubj     False   False   \n",
       "8                dice              decir   VERB   csubj     False   False   \n",
       "9                   :                  :  PUNCT   punct     False   False   \n",
       "10                  \"                  \"  PUNCT   punct     False   False   \n",
       "11                OMG                OMG  PROPN     obj     False   False   \n",
       "12                  !                  !  PUNCT   punct     False   False   \n",
       "13                 El                 el    DET     det     False   False   \n",
       "14              seÃ±or              seÃ±or   NOUN   nsubj     False   False   \n",
       "15             Carlos             Carlos  PROPN   appos     False   False   \n",
       "16             rompiÃ³             romper   VERB    ROOT     False   False   \n",
       "17                 el                 el    DET     det     False   False   \n",
       "18            control            control   NOUN     obj     False   False   \n",
       "19                del                del    ADP    case     False   False   \n",
       "20          televisor          televisor   NOUN    nmod     False   False   \n",
       "21                hoy                hoy    ADV  advmod     False   False   \n",
       "22                  y                  y  CCONJ      cc     False   False   \n",
       "23               tuve              tener   VERB    conj     False   False   \n",
       "24                que                que  SCONJ      cc     False   False   \n",
       "25            comprar            comprar   VERB    conj     False   False   \n",
       "26               otro               otro   PRON     obj     False   False   \n",
       "27                 en                 en    ADP    case     False   False   \n",
       "28  www.amazon.com.mx  www.amazon.com.mx  PROPN     obl     False    True   \n",
       "29                  \"                  \"  PUNCT   punct     False   False   \n",
       "30                  .                  .  PUNCT   punct     False   False   \n",
       "\n",
       "            next_text  \n",
       "0               llegÃ³  \n",
       "1               llegÃ³  \n",
       "2               email  \n",
       "3               llegÃ³  \n",
       "4              correo  \n",
       "5               llegÃ³  \n",
       "6              correo  \n",
       "7                dice  \n",
       "8               llegÃ³  \n",
       "9                 OMG  \n",
       "10                OMG  \n",
       "11               dice  \n",
       "12                OMG  \n",
       "13              seÃ±or  \n",
       "14             rompiÃ³  \n",
       "15              seÃ±or  \n",
       "16             rompiÃ³  \n",
       "17            control  \n",
       "18             rompiÃ³  \n",
       "19          televisor  \n",
       "20            control  \n",
       "21             rompiÃ³  \n",
       "22               tuve  \n",
       "23             rompiÃ³  \n",
       "24            comprar  \n",
       "25               tuve  \n",
       "26            comprar  \n",
       "27  www.amazon.com.mx  \n",
       "28            comprar  \n",
       "29             rompiÃ³  \n",
       "30             rompiÃ³  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load spaCy Spanish pipeline optimized\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "# ejemplo\n",
    "enunciado = 'Me llegÃ³ un email al correo leo234@gmail.com que dice: \"OMG! El seÃ±or Carlos rompiÃ³ el control del televisor hoy y tuve que \\\n",
    "comprar otro en www.amazon.com.mx\".'\n",
    "\n",
    "# volver el enunciado un objeto tipo NLP\n",
    "doc = nlp(enunciado) #(sentences[0])\n",
    "print(\"Enunciado:\\n\",doc.text,\"\\n\")\n",
    "\n",
    "# Para cada token (palabra/cadena) se obtienen distintas caracterÃ­sticas:\n",
    "# - texto\n",
    "# - tag con tipo de texto: noun, verb, determinant, adverb, conjunction\n",
    "# - dep: dependenxy\n",
    "# - like_email: identifica si el token es un email\n",
    "# - like_url: identifica si el token es una pÃ¡gina web\n",
    "list_tokens = []\n",
    "for token in doc:\n",
    "    # print(token.text, token.pos_, token.dep_, token.like_email)\n",
    "    list_tokens.append([token.text,token.lemma_,token.pos_,token.dep_,token.like_email,\n",
    "                        token.like_url, token.head.text])\n",
    "\n",
    "# Revisar algunas de las caracterÃ­sticas de cada token\n",
    "pd.DataFrame(list_tokens, columns=['text','lemma','pos','dep','is_email','is_url','next_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preproceso con spaCy\n",
    "Ejemplo de funciÃ³n para preproceso usando spaCy, Regex y mÃ©todos de strings, comparando resultados con el del preproceso que se vio al inicio de este Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text,\n",
    "               min_token_len = 2,\n",
    "               irrelevant_pos = ['PRON', 'SPACE', 'PUNCT', 'ADV', 'ADP', 'CCONJ', 'AUX', 'PRP'],\n",
    "               avoid_entities = ['PERSON', 'ORG', 'LOC', 'GPE']):\n",
    "    # note: Didn't use the following options in the `preprocess_comments`\n",
    "    #    - 'PROPN', erase proper names, but also words as orange.\n",
    "    #    - 'DET', removes the word 'no', which changes the meaning.\n",
    "    \"\"\"\n",
    "    Function that identify sensible information, anonymize and transforms\n",
    "    the data in a useful format for using with tokens.\n",
    "    Parameters\n",
    "    -------------\n",
    "    text : (list)\n",
    "        the list of text to be preprocessed\n",
    "    irrelevant_pos : (list)\n",
    "        a list of irrelevant 'pos' tags\n",
    "    avoid_entities : (list)\n",
    "        a list of entity labels to be avoided\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    (list) list of preprocessed text\n",
    "\n",
    "    Example\n",
    "    -------------\n",
    "    example = [\"Hello, I'm George and I love swimming!\",\n",
    "                \"I am a really good cook; what about you?\",\n",
    "                \"Contact me at george23@gmail.com\"]\n",
    "    preprocess(example)\n",
    "    (output:) ['hello love swimming', 'good cook', 'contact']\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    others = [\"'s\", \"the\", \"that\", \"this\", \"to\", \"-PRON-\"]\n",
    "    # comment: \"-PRON-\" is a lemma for \"my\", \"your\", etc.\n",
    "\n",
    "    # function\n",
    "    for sent in text:\n",
    "        # <string methods>\n",
    "        sent = str(sent).lower()\n",
    "        \n",
    "        # <regex>\n",
    "        sent = re.sub(r\"(F|f)acebook\", \"social media\", sent)\n",
    "        sent = re.sub(r\"(T|t)witter\", \"social media\", sent)\n",
    "        sent = re.sub(r\"(I|i)nstagram\", \"social media\", sent)\n",
    "        \n",
    "        result_sent = []\n",
    "        \n",
    "        # <spaCy>\n",
    "        doc = nlp(sent)\n",
    "        entities = [str(ent) for ent in doc.ents if ent.label_ in avoid_entities]\n",
    "                   # This helps to detect names of persons, organization and dates\n",
    "        for token in doc:            \n",
    "            if (token.like_email or\n",
    "                token.like_url or\n",
    "                token.pos_ in irrelevant_pos or\n",
    "                str(token) in entities or\n",
    "                str(token.lemma_) in others or\n",
    "                len(token) < min_token_len):\n",
    "                continue\n",
    "            else:\n",
    "                result_sent.append(token.lemma_)\n",
    "        result.append(result_sent)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess tweets\n",
    "df['tweet_spacy_preprocess'] = preprocess(df['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_clean</th>\n",
       "      <th>tweet_spacy_preprocess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@EugeniaLeon Hay sra. Si de por sÃ­ me daba flo...</td>\n",
       "      <td>[@eugenialeon, sra, si, daba, flojera, ahora, ...</td>\n",
       "      <td>[@eugenialeon, si, dar, flojera, bueno, porque...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@JenniferCuriel9 @ClaudioXGG La MEGAMARCHA ğŸ‘‡ğŸ˜\\...</td>\n",
       "      <td>[@jennifercuriel9, @claudioxgg, megamarcha, ğŸ‘‡ğŸ˜...</td>\n",
       "      <td>[@jennifercuriel9, @claudioxgg, el, megamarcha]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@_VicenteSerrano @lopezobrador_ ğŸ˜‚ğŸ˜‚ğŸ˜‚ doliÃ³??? #...</td>\n",
       "      <td>[@vicenteserrano, @lopezobrador, ğŸ˜‚ğŸ˜‚ğŸ˜‚, doliÃ³, #...</td>\n",
       "      <td>[@_vicenteserrano, @lopezobrador, doler, eline...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...</td>\n",
       "      <td>[@amadoelquelolea, @scjn, acuerdo, si, voy, vi...</td>\n",
       "      <td>[@scjn, acuerdo, si, ir, el, visita, cuanta, v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@EmilioAlvarezI El PRI de los 70â€™s ha vuelto. ...</td>\n",
       "      <td>[@emilioalvarezi, pri, 70â€™s, vuelto, @lopezobr...</td>\n",
       "      <td>[@emilioalvarezi, el, el, 70â€™, volver, @lopezo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Verdad que si lo quieren desaparecer?\\nSÃ³lo lo...</td>\n",
       "      <td>[verdad, si, quieren, desaparecer, sÃ³lo, abyec...</td>\n",
       "      <td>[verdad, que, si, querer, desaparecer, el, aby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>@lopezobrador_ Y AMLO en vez de gobernar, sale...</td>\n",
       "      <td>[@lopezobrador, amlo, vez, gobernar, sale, des...</td>\n",
       "      <td>[@lopezobrador, amlo, vez, gobernar, salir, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Lo Ãºnico que saben es robar, mentir y destruir...</td>\n",
       "      <td>[Ãºnico, saben, robar, mentir, destruir, #moren...</td>\n",
       "      <td>[Ãºnico, saber, robar, mentir, destruir, morena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>@EugeniaLeon @lopezobrador_ #ElINENoSeToca \\n#...</td>\n",
       "      <td>[@eugenialeon, @lopezobrador, #elinenosetoca, ...</td>\n",
       "      <td>[@eugenialeon, @lopezobrador, elinenosetoco, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>@santiagobaeza @lopezobrador_ la gente se hart...</td>\n",
       "      <td>[@santiagobaeza, @lopezobrador, gente, hartÃ³, ...</td>\n",
       "      <td>[@santiagobaeza, el, gente, hartar, su, gobier...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet  \\\n",
       "0    @EugeniaLeon Hay sra. Si de por sÃ­ me daba flo...   \n",
       "1    @JenniferCuriel9 @ClaudioXGG La MEGAMARCHA ğŸ‘‡ğŸ˜\\...   \n",
       "2    @_VicenteSerrano @lopezobrador_ ğŸ˜‚ğŸ˜‚ğŸ˜‚ doliÃ³??? #...   \n",
       "3    @Amadoelquelolea @SCJN Muy de acuerdo ! \\nYo s...   \n",
       "4    @EmilioAlvarezI El PRI de los 70â€™s ha vuelto. ...   \n",
       "..                                                 ...   \n",
       "995  Verdad que si lo quieren desaparecer?\\nSÃ³lo lo...   \n",
       "996  @lopezobrador_ Y AMLO en vez de gobernar, sale...   \n",
       "997  Lo Ãºnico que saben es robar, mentir y destruir...   \n",
       "998  @EugeniaLeon @lopezobrador_ #ElINENoSeToca \\n#...   \n",
       "999  @santiagobaeza @lopezobrador_ la gente se hart...   \n",
       "\n",
       "                                           tweet_clean  \\\n",
       "0    [@eugenialeon, sra, si, daba, flojera, ahora, ...   \n",
       "1    [@jennifercuriel9, @claudioxgg, megamarcha, ğŸ‘‡ğŸ˜...   \n",
       "2    [@vicenteserrano, @lopezobrador, ğŸ˜‚ğŸ˜‚ğŸ˜‚, doliÃ³, #...   \n",
       "3    [@amadoelquelolea, @scjn, acuerdo, si, voy, vi...   \n",
       "4    [@emilioalvarezi, pri, 70â€™s, vuelto, @lopezobr...   \n",
       "..                                                 ...   \n",
       "995  [verdad, si, quieren, desaparecer, sÃ³lo, abyec...   \n",
       "996  [@lopezobrador, amlo, vez, gobernar, sale, des...   \n",
       "997  [Ãºnico, saben, robar, mentir, destruir, #moren...   \n",
       "998  [@eugenialeon, @lopezobrador, #elinenosetoca, ...   \n",
       "999  [@santiagobaeza, @lopezobrador, gente, hartÃ³, ...   \n",
       "\n",
       "                                tweet_spacy_preprocess  \n",
       "0    [@eugenialeon, si, dar, flojera, bueno, porque...  \n",
       "1      [@jennifercuriel9, @claudioxgg, el, megamarcha]  \n",
       "2    [@_vicenteserrano, @lopezobrador, doler, eline...  \n",
       "3    [@scjn, acuerdo, si, ir, el, visita, cuanta, v...  \n",
       "4    [@emilioalvarezi, el, el, 70â€™, volver, @lopezo...  \n",
       "..                                                 ...  \n",
       "995  [verdad, que, si, querer, desaparecer, el, aby...  \n",
       "996  [@lopezobrador, amlo, vez, gobernar, salir, de...  \n",
       "997  [Ãºnico, saber, robar, mentir, destruir, morena...  \n",
       "998  [@eugenialeon, @lopezobrador, elinenosetoco, y...  \n",
       "999  [@santiagobaeza, el, gente, hartar, su, gobier...  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['tweet','tweet_clean','tweet_spacy_preprocess']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Referencias\n",
    "- [Python String Methods](https://docs.python.org/3/library/stdtypes.html) in Python Documentation.\n",
    "- [Text Preprocessing in NLP with Python codes](https://www.analyticsvidhya.com/blog/2021/06/text-preprocessing-in-nlp-with-python-codes/) by Deepanshi, in Analytics Vidhya.\n",
    "- LibrerÃ­a de Python [*Natural Language Toolkit* - `NLTK`](https://www.nltk.org/index.html)\n",
    "- LibrerÃ­a de Python [*Regular expression operations* - `re`](https://docs.python.org/3/library/re.html)\n",
    "- Material pÃºblico del curso [DSCI 575: Advanced Machine Learning](https://github.com/UBC-MDS/DSCI_575_adv-mach-learn) de UBC MDS.\n",
    "- Python script [preprocess.py](https://github.com/vcuspinera/UBC_MDS_Capstone_BCStats/blob/master/src/data/preprocess.py) del Capstone project de UBC MDS y BC Stats, por Sukriti Trehan, Karanpal Singh, Carlina Kim y Victor Cuspinera."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
